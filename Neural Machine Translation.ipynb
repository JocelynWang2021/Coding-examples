{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35e22f542837d636834ad6e869d22beb",
     "grade": false,
     "grade_id": "cell-5690119ead85e67e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Checklist for submission\n",
    "\n",
    "It is extremely important to make sure that:\n",
    "\n",
    "1. Everything runs as expected (no bugs when running cells);\n",
    "2. The output from each cell corresponds to its code (don't change any cell's contents without rerunning it afterwards);\n",
    "3. All outputs are present (don't delete any of the outputs);\n",
    "4. Fill in all the places that say `# YOUR CODE HERE`, or \"**Your answer:** (fill in here)\".\n",
    "5. Never copy/paste any notebook cells. Inserting new cells is allowed, but it should not be necessary.\n",
    "6. The notebook contains some hidden metadata which is important during our grading process. **Make sure not to corrupt any of this metadata!** The metadata may for example be corrupted if you copy/paste any notebook cells, or if you perform an unsuccessful git merge / git pull. It may also be pruned completely if using Google Colab, so watch out for this. Searching for \"nbgrader\" when opening the notebook in a text editor should take you to the important metadata entries.\n",
    "7. Although we will try our very best to avoid this, it may happen that bugs are found after an assignment is released, and that we will push an updated version of the assignment to GitHub. If this happens, it is important that you update to the new version, while making sure the notebook metadata is properly updated as well. The safest way to make sure nothing gets messed up is to start from scratch on a clean updated version of the notebook, copy/pasting your code from the cells of the previous version into the cells of the new version.\n",
    "8. If you need to have multiple parallel versions of this notebook, make sure not to move them to another directory.\n",
    "9. Although not forced to work exclusively in the course Docker environment, you need to make sure that the notebook will run in that environment, i.e. that you have not added any additional dependencies.\n",
    "\n",
    "Failing to meet any of these requirements might lead to either a subtraction of POEs (at best) or a request for resubmission (at worst).\n",
    "\n",
    "We advise you the following steps before submission for ensuring that requirements 1, 2, and 3 are always met: **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). This might require a bit of time, so plan ahead for this (and possibly use Google Cloud's GPU in HA1 and HA2 for this step). Finally press the \"Save and Checkout\" button before handing in, to make sure that all your changes are saved to this .ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6bb874a16c1ff767ac0f37ce0491265",
     "grade": false,
     "grade_id": "cell-774c93bf6433de68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fill in name of notebook file\n",
    "This might seem silly, but the version check below needs to know the filename of the current notebook, which is not trivial to find out programmatically.\n",
    "\n",
    "You might want to have several parallel versions of the notebook, and it is fine to rename the notebook as long as it stays in the same directory. **However**, if you do rename it, you also need to update its own filename below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fname = \"HA2-Part2.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a025ba528a4e9c11fc54be126fdffab0",
     "grade": false,
     "grade_id": "cell-5676bcf768a7f9be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fill in group number and member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = \"67\"\n",
    "NAME1 = \"Tobias Sundell\"\n",
    "NAME2 = \"Qingbo Zhu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42f960a95815e1aa3ce8132fcec59cd9",
     "grade": false,
     "grade_id": "cell-a15fe781533d9590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Check Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fef548ba4fe8319321134f43c6c479f",
     "grade": false,
     "grade_id": "cell-2b9c2390ee464c39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from platform import python_version_tuple\n",
    "assert python_version_tuple()[:2] == ('3','7'), \"You are not running Python 3.7. Make sure to run Python through the course Docker environment, or alternatively in the provided Conda environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15ec4309f1e85f6e17bda73b9b6f48a2",
     "grade": false,
     "grade_id": "cell-4869b45600ce82f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Check that notebook server has access to all required resources, and that notebook has not moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "929b996cdd0fd4b8120fad773b146c86",
     "grade": false,
     "grade_id": "cell-122ac3d9100b8afb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "nb_dirname = os.path.abspath('')\n",
    "assert nb_dirname != '/workspace', \\\n",
    "    '[ERROR] The notebook server appears to have been started via Docker, at the same directory as the assignment. Make sure to start it at least one level above the assignment.'\n",
    "assignment_name = os.path.basename(nb_dirname)\n",
    "assert assignment_name in ['IHA1', 'IHA2', 'HA1', 'HA2', 'HA3'], \\\n",
    "    '[ERROR] The notebook appears to have been moved from its original directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f09f40b5350db83232189137c550f0a1",
     "grade": false,
     "grade_id": "cell-2455deee513cd39c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Verify correct nb_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a78c7227b049bb147e6c363affb6dae8",
     "grade": false,
     "grade_id": "cell-0472e2fd710f1d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>if(\"HA2-Part2.ipynb\" != IPython.notebook.notebook_name) { alert(\"You have filled in nb_fname = \\\"HA2-Part2.ipynb\\\", but this does not seem to match the notebook filename \\\"\" + IPython.notebook.notebook_name + \"\\\".\"); }</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "try:\n",
    "    display(HTML(r'<script>if(\"{nb_fname}\" != IPython.notebook.notebook_name) {{ alert(\"You have filled in nb_fname = \\\"{nb_fname}\\\", but this does not seem to match the notebook filename \\\"\" + IPython.notebook.notebook_name + \"\\\".\"); }}</script>'.format(nb_fname=nb_fname)))\n",
    "except NameError:\n",
    "    assert False, 'Make sure to fill in the nb_fname variable above!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98d88d8e8da19693053764f29dcc591d",
     "grade": false,
     "grade_id": "cell-ceacb1adcae4783d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Verify that your notebook is up-to-date and not corrupted in any way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb700528d4644601c1a8c91ef1d84635",
     "grade": false,
     "grade_id": "cell-f5a59288e11b4aec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching current notebook against the following URL:\n",
      "http://raw.githubusercontent.com/JulianoLagana/deep-machine-learning/master/home-assignments/HA2/HA2-Part2.ipynb\n",
      "[SUCCESS] No major notebook mismatch found when comparing to latest GitHub version. (There might be minor updates, but even that is the case, submitting your work based on this notebook version would be acceptable.)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from ha_utils import check_notebook_uptodate_and_not_corrupted\n",
    "check_notebook_uptodate_and_not_corrupted(nb_dirname, nb_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be161193815d6c8b524adf7b70ce7543",
     "grade": false,
     "grade_id": "cell-44e7522eff275a3b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "![test](data/translate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b79723d87eadd780ec89fa4452ccc87",
     "grade": false,
     "grade_id": "cell-3c556a39514d3d6c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 2 - Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "894ae9ce85da0384a36fb57960330fa1",
     "grade": false,
     "grade_id": "cell-1531dbb9354dac88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In this task you will build a system that uses recurrent neural networks to translate sentences from English to Spanish! \n",
    "\n",
    "Before we start coding anything, it's important to clear up some details about neural machine translation and make sure everyone is on the same page regarding conventions, etc. Please read the next section carefully and make sure you understand the specifics of the solution we will develop in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "409886b827fd4c4421e5946574a6958f",
     "grade": false,
     "grade_id": "cell-a4bff0f2271fff88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.0 Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0af648058036adc9d87713a4b89876c0",
     "grade": false,
     "grade_id": "cell-1d1463757139054a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For this translation task, we'll use an encoder-decoder architecture. The input sentence (in English) will be first processed by the encoder, which will output its hidden state at the last time-step. After that, this hidden state will be fed as the initial state for the decoder, which will generate the output sentence (in Spanish). The following diagram illustrates the process:\n",
    "\n",
    "![nmt_teacher_forcing](data/nmt_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d2e5b2678c07d902f4027f108cf5fc5",
     "grade": false,
     "grade_id": "cell-c9f6b1971b7c0493",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We feed one word of the input sentence at a time (first `i`, then `am`, then `happy`) to the encoder, which processes it and computes its next hidden state. Once the last word of the input sentence is processed by the encoder, we feed its current hidden state to the decoder.\n",
    "\n",
    "The decoder then uses this hidden state as initial state, together with a special word token that we feed as input, which signifies the \"start of sentence\", `<SOS>`. This tells the decoder it should start generating the output sentence.\n",
    "\n",
    "The decoder then produces a probability distribution over possible spanish words for the first position. We sample from this distribution to obtain one word, which in this case the sample was `estoy`. This output is now the first word of the generated translation. In order to generate the next word, we feed the sample `estoy` as input to the decoder in the next time-step, which then produces a new probability distribution over possible spanish words again, from which we sampled `feliz` in the example. This process continues until it produces the special word token `<EOS>`, which signifies the end of the sentence (or until a maximum number of words have been generated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ad4295974edfe6dd20f1ec1d1dbc5e0",
     "grade": false,
     "grade_id": "cell-5dfda0f0cbf95851",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Because of this connection from output to input, this type of architecture can be challenging to train. One commonly used technique to circumvent this problem is called *teacher forcing*. In it, instead of feeding the output at time-step $t$ as input to time-step $t+1$, we use as input the *ground-truth label* for time-step $t+1$. The following diagram illustrates it:\n",
    "\n",
    "![nmt_teacher_forcing](data/nmt_teacher_forcing.png)\n",
    "\n",
    "Note how in this example the model incorrectly predicted `estas` as the first word in the translation. However, instead of feeding it as input to the next time-step, and making it more likely to also misclassify the next word, we feed the *ground-truth label* as input, `estoy`, here shown in green. We continue this process until we fed all of the ground-truth words to the decoder (regardless of whether the model predicts `<EOS>` or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9949acfd493ff4800c33f8e66923f05",
     "grade": false,
     "grade_id": "cell-438e7e0fcd4c4091",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce9b564cefed1357a0db712c6d9a68be",
     "grade": false,
     "grade_id": "cell-4af1474eab90f437",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that it's clear which kind of system we will develop, we can start the task by loading the data we will use.\n",
    "\n",
    "The data for this task is present in the file `data/eng-spa.txt` (obtained from [here](https://www.manythings.org/anki/)), a text file comprised of thousands of sentences in English and their counterpart Spanish translations. Before continuing, take a look at the file now to see its internal structure.\n",
    "\n",
    "We'll load the sentences in this file using the provided helper function `get_data_from_file`. This function loads a subset of the entire dataset (no long sentences, no sentences with rare words, etc) for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eb5a27fde7a820765d9daf3f55fae3e",
     "grade": false,
     "grade_id": "cell-f846c494c826a310",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from utils.load_sentences import get_data_from_file, SOS_word_idx, EOS_word_idx, PAD_word_idx\n",
    "pairs, input_lang, output_lang = get_data_from_file('data/eng-spa.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20a426fcdf0ba683bf63369d52e7a418",
     "grade": false,
     "grade_id": "cell-c2fb9d37d6959f02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The first loaded object, `pairs`, is a list of all the loaded pairs of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f9cb9d771b742b30ef13947a8e822b5",
     "grade": false,
     "grade_id": "cell-1a58d8ec5834578f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33941"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cf7e1869f95a864bf11812110126b53",
     "grade": false,
     "grade_id": "cell-06c2f57520370ab9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go', 've'],\n",
       " ['go', 'vete'],\n",
       " ['go', 'vaya'],\n",
       " ['who', 'quién'],\n",
       " ['fire', 'fuego'],\n",
       " ['fire', 'incendio'],\n",
       " ['help', 'ayuda'],\n",
       " ['stop', 'para'],\n",
       " ['wait', 'espera'],\n",
       " ['go now', 've ahora mismo'],\n",
       " ['go now', 'vaya ahora mismo'],\n",
       " ['go now', 've ya'],\n",
       " ['go now', 'vaya ya'],\n",
       " ['got it', 'lo tengo'],\n",
       " ['he ran', 'él corrió'],\n",
       " ['i know', 'yo lo sé'],\n",
       " ['i lost', 'perdí'],\n",
       " ['i work', 'estoy trabajando'],\n",
       " ['listen', 'escucha'],\n",
       " ['no way', 'no puede ser'],\n",
       " ['no way', 'de ninguna manera'],\n",
       " ['no way', 'de ninguna manera'],\n",
       " ['no way', 'imposible'],\n",
       " ['no way', 'de eso nada'],\n",
       " ['really', 'en serio'],\n",
       " ['really', 'la verdad'],\n",
       " ['thanks', 'gracias'],\n",
       " ['thanks', 'gracias'],\n",
       " ['why me', 'por qué yo'],\n",
       " ['be good', 'sé bueno'],\n",
       " ['be good', 'sé buena'],\n",
       " ['be good', 'sea buena'],\n",
       " ['be good', 'sea bueno'],\n",
       " ['be nice', 'sé agradable'],\n",
       " ['come in', 'entre'],\n",
       " ['come in', 'pase'],\n",
       " ['get out', 'sal'],\n",
       " ['go away', 'vete de aquí'],\n",
       " ['go away', 'largo'],\n",
       " ['go away', 'vete ya'],\n",
       " ['go away', 'a la calle'],\n",
       " ['go away', 'vete de aquí'],\n",
       " ['go away', 'largo'],\n",
       " ['go away', 'vete ya'],\n",
       " ['go home', 'vete a casa'],\n",
       " ['hang on', 'espera'],\n",
       " ['hang on', 'espera un momento'],\n",
       " ['hang on', 'un segundo'],\n",
       " ['he came', 'él vino'],\n",
       " ['hold it', 'espera'],\n",
       " ['i agree', 'estoy de acuerdo'],\n",
       " ['i agree', 'de acuerdo'],\n",
       " ['i tried', 'lo intenté'],\n",
       " ['i ll go', 'iré'],\n",
       " ['i m tom', 'soy tom'],\n",
       " ['i m fit', 'estoy en forma'],\n",
       " ['i m old', 'soy viejo'],\n",
       " ['it s ok', 'está bien'],\n",
       " ['it s me', 'soy yo'],\n",
       " ['it s me', 'soy yo'],\n",
       " ['join us', 'sé parte nuestra'],\n",
       " ['me too', 'yo también'],\n",
       " ['open up', 'abre'],\n",
       " ['perfect', 'perfecto'],\n",
       " ['shut up', 'cierra la boca'],\n",
       " ['so long', 'hasta la vista'],\n",
       " ['so long', 'hasta luego'],\n",
       " ['tom ate', 'tom comió'],\n",
       " ['tom ran', 'tom corrió'],\n",
       " ['tom won', 'tom ganó'],\n",
       " ['we know', 'lo sabemos'],\n",
       " ['who ate', 'quién comió'],\n",
       " ['who ran', 'quién corrió'],\n",
       " ['who won', 'quién ganó'],\n",
       " ['why not', 'por qué no'],\n",
       " ['be a man', 'sé un hombre'],\n",
       " ['don t go', 'no te vayas'],\n",
       " ['get away', 'vete de aquí'],\n",
       " ['get away', 'largo'],\n",
       " ['get away', 'vete ya'],\n",
       " ['get down', 'abajo'],\n",
       " ['get lost', 'vete de aquí'],\n",
       " ['get lost', 'largo'],\n",
       " ['get lost', 'vete ya'],\n",
       " ['get real', 'abre los ojos'],\n",
       " ['go ahead', 'adelante'],\n",
       " ['go ahead', 'adelante'],\n",
       " ['go on in', 'entre'],\n",
       " ['good job', 'buen trabajo'],\n",
       " ['he spoke', 'él habló'],\n",
       " ['help tom', 'ayuda a tom'],\n",
       " ['i am old', 'estoy viejo'],\n",
       " ['i ate it', 'me lo comí'],\n",
       " ['i ate it', 'me la comí'],\n",
       " ['i can go', 'puedo ir'],\n",
       " ['i did ok', 'lo hice bien'],\n",
       " ['i did it', 'lo hice'],\n",
       " ['i forgot', 'lo olvidé'],\n",
       " ['i get it', 'lo entiendo'],\n",
       " ['i got it', 'lo tengo'],\n",
       " ['i saw it', 'lo vi'],\n",
       " ['i stayed', 'me quedé'],\n",
       " ['i m back', 'he vuelto'],\n",
       " ['i m back', 'estoy de vuelta'],\n",
       " ['i m done', 'he terminado'],\n",
       " ['i m free', 'soy libre'],\n",
       " ['i m free', 'yo soy libre'],\n",
       " ['i m full', 'estoy lleno'],\n",
       " ['i m full', 'estoy llena'],\n",
       " ['i m here', 'estoy aquí'],\n",
       " ['i m home', 'estoy en casa'],\n",
       " ['i m hurt', 'estoy herido'],\n",
       " ['i m mean', 'soy malo'],\n",
       " ['i m next', 'me toca a mí'],\n",
       " ['i m poor', 'soy pobre'],\n",
       " ['i m rich', 'soy rica'],\n",
       " ['i m rich', 'soy rico'],\n",
       " ['i m sick', 'estoy enferma'],\n",
       " ['it works', 'funciona'],\n",
       " ['it s tom', 'es tom'],\n",
       " ['it s fun', 'es divertido'],\n",
       " ['it s new', 'es nuevo'],\n",
       " ['it s old', 'es viejo'],\n",
       " ['it s red', 'es rojo'],\n",
       " ['it s sad', 'es triste'],\n",
       " ['keep out', 'no entrar'],\n",
       " ['leave me', 'déjame'],\n",
       " ['let s go', 'vamos'],\n",
       " ['look out', 'cuidado'],\n",
       " ['may i go', 'puedo ir'],\n",
       " ['she came', 'ella vino'],\n",
       " ['she died', 'ella murió'],\n",
       " ['speak up', 'habla más fuerte'],\n",
       " ['speak up', 'habla más alto'],\n",
       " ['stand by', 'un momento'],\n",
       " ['stand up', 'de pie'],\n",
       " ['tom came', 'tom vino'],\n",
       " ['tom died', 'tom ha muerto'],\n",
       " ['tom fell', 'tom se cayó'],\n",
       " ['tom knew', 'tom lo sabía'],\n",
       " ['tom left', 'tom se fue'],\n",
       " ['tom lost', 'tom perdió'],\n",
       " ['too late', 'demasiado tarde'],\n",
       " ['try some', 'prueba un poco'],\n",
       " ['try this', 'prueba esto'],\n",
       " ['use this', 'usa esto'],\n",
       " ['we agree', 'estamos de acuerdo'],\n",
       " ['we re ok', 'estamos bien'],\n",
       " ['what for', 'para qué'],\n",
       " ['what fun', 'qué divertido'],\n",
       " ['who am i', 'quién soy yo'],\n",
       " ['who came', 'quién vino'],\n",
       " ['who died', 'quién murió'],\n",
       " ['who fell', 'quién se cayó'],\n",
       " ['who quit', 'quién se ha ido'],\n",
       " ['who quit', 'quién lo ha dejado'],\n",
       " ['who s he', 'quién es él'],\n",
       " ['you lost', 'has perdido'],\n",
       " ['you lost', 'habéis perdido'],\n",
       " ['you lost', 'perdió usted'],\n",
       " ['you lost', 'ha perdido usted'],\n",
       " ['you lost', 'han perdido ustedes'],\n",
       " ['after you', 'después de ti'],\n",
       " ['after you', 'tú primero'],\n",
       " ['after you', 'usted primero'],\n",
       " ['after you', 'después de usted'],\n",
       " ['after you', 'después de vosotras'],\n",
       " ['call home', 'llama a casa'],\n",
       " ['can we go', 'podemos ir'],\n",
       " ['come back', 'vuelve'],\n",
       " ['come here', 'ven'],\n",
       " ['come home', 'ven a casa'],\n",
       " ['come over', 'venga aquí'],\n",
       " ['come soon', 'vuelve pronto'],\n",
       " ['go for it', 've a por ello'],\n",
       " ['go get it', 've a por ello'],\n",
       " ['go get it', 'vete a por ello'],\n",
       " ['go to bed', 'vete a la cama'],\n",
       " ['have some', 'toma algo'],\n",
       " ['he is old', 'él es viejo'],\n",
       " ['he is old', 'él es anciano'],\n",
       " ['he smiled', 'sonrió'],\n",
       " ['he s good', 'él es bueno'],\n",
       " ['he s rich', 'él es rico'],\n",
       " ['he s rich', 'es rico'],\n",
       " ['here i am', 'acá estoy'],\n",
       " ['how s tom', 'cómo está tom'],\n",
       " ['i am busy', 'estoy ocupada'],\n",
       " ['i am full', 'estoy lleno'],\n",
       " ['i am full', 'estoy llena'],\n",
       " ['i am good', 'soy bueno'],\n",
       " ['i am here', 'estoy aquí'],\n",
       " ['i am sick', 'estoy enferma'],\n",
       " ['i can run', 'puedo correr'],\n",
       " ['i can run', 'sé correr'],\n",
       " ['i gave up', 'lo dejé'],\n",
       " ['i get you', 'te entiendo'],\n",
       " ['i hate it', 'lo odio'],\n",
       " ['i hope so', 'eso espero'],\n",
       " ['i knew it', 'lo sabía'],\n",
       " ['i like it', 'me gusta'],\n",
       " ['i love it', 'me encanta'],\n",
       " ['i mean it', 'hablo en serio'],\n",
       " ['i mean it', 'lo digo en serio'],\n",
       " ['i mean it', 'hablo en serio'],\n",
       " ['i need it', 'lo necesito'],\n",
       " ['i saw tom', 'vi a tom'],\n",
       " ['i saw him', 'le vi'],\n",
       " ['i saw him', 'lo vi'],\n",
       " ['i saw one', 'vi uno'],\n",
       " ['i saw one', 'vi a uno'],\n",
       " ['i saw one', 'veía a uno'],\n",
       " ['i saw you', 'te vi'],\n",
       " ['i saw you', 'te he visto'],\n",
       " ['i see tom', 'veo a tom'],\n",
       " ['i ll work', 'voy a trabajar'],\n",
       " ['i m a man', 'soy un hombre'],\n",
       " ['i m alone', 'estoy solo'],\n",
       " ['i m alone', 'estoy sola'],\n",
       " ['i m alone', 'yo estoy solo'],\n",
       " ['i m alone', 'yo estoy sola'],\n",
       " ['i m angry', 'estoy enojado'],\n",
       " ['i m broke', 'estoy sin dinero'],\n",
       " ['i m crazy', 'estoy loco'],\n",
       " ['i m drunk', 'estoy borracho'],\n",
       " ['i m first', 'soy el primero'],\n",
       " ['i m first', 'voy el primero'],\n",
       " ['i m first', 'me toca primero'],\n",
       " ['i m first', 'yo voy primero'],\n",
       " ['i m happy', 'soy feliz'],\n",
       " ['i m happy', 'estoy feliz'],\n",
       " ['i m ready', 'estoy listo'],\n",
       " ['i m ready', 'estoy listo'],\n",
       " ['i m sorry', 'lo siento'],\n",
       " ['i m tired', 'yo estoy cansado'],\n",
       " ['i m tired', 'yo estoy cansada'],\n",
       " ['i m yours', 'soy tuyo'],\n",
       " ['i m yours', 'soy tuya'],\n",
       " ['i ve lost', 'he perdido'],\n",
       " ['is tom ok', 'está bien tom'],\n",
       " ['is tom in', 'está tom'],\n",
       " ['is it bad', 'es malo'],\n",
       " ['is it far', 'está lejos'],\n",
       " ['is it you', 'eres tú'],\n",
       " ['it failed', 'no lo consiguió'],\n",
       " ['it is new', 'es nuevo'],\n",
       " ['it s', 'son las'],\n",
       " ['it s cold', 'hace frío'],\n",
       " ['it s cold', 'está frío'],\n",
       " ['it s cool', 'está frío'],\n",
       " ['it s dark', 'está oscuro'],\n",
       " ['it s done', 'está listo'],\n",
       " ['it s fine', 'está perfecto'],\n",
       " ['it s good', 'está bien'],\n",
       " ['it s good', 'es bueno'],\n",
       " ['it s here', 'está aquí'],\n",
       " ['it s late', 'es tarde'],\n",
       " ['it s mine', 'es mío'],\n",
       " ['it s mine', 'es mía'],\n",
       " ['it s nice', 'es agradable'],\n",
       " ['it s nice', 'hace buen tiempo'],\n",
       " ['it s over', 'se terminó'],\n",
       " ['it s time', 'ha llegado el momento'],\n",
       " ['it s time', 'es la hora'],\n",
       " ['it s time', 'es el momento'],\n",
       " ['it s time', 'ha llegado la hora'],\n",
       " ['it s true', 'es verdad'],\n",
       " ['it s true', 'es verdad'],\n",
       " ['it s work', 'es mi trabajo'],\n",
       " ['leave now', 'ahora vete'],\n",
       " ['let me in', 'déjame entrar'],\n",
       " ['look away', 'mira para otro lado'],\n",
       " ['look back', 'mira hacia atrás'],\n",
       " ['look back', 'mira atrás'],\n",
       " ['look here', 'mira aquí'],\n",
       " ['move over', 'deja sitio'],\n",
       " ['move over', 'deja pasar'],\n",
       " ['please go', 'por favor ve'],\n",
       " ['please go', 'por favor vete'],\n",
       " ['read this', 'lee esto'],\n",
       " ['seriously', 'en serio'],\n",
       " ['she tried', 'ella lo intentó'],\n",
       " ['she s hot', 'está como un tren'],\n",
       " ['she s hot', 'está buena'],\n",
       " ['stay away', 'fuera'],\n",
       " ['stop here', 'para aquí'],\n",
       " ['stop that', 'para eso'],\n",
       " ['take mine', 'toma el mío'],\n",
       " ['take this', 'toma esto'],\n",
       " ['thank you', 'gracias'],\n",
       " ['thank you', 'gracias a ti'],\n",
       " ['thank you', 'gracias'],\n",
       " ['that s it', 'eso es'],\n",
       " ['that s me', 'soy yo'],\n",
       " ['that s me', 'ese soy yo'],\n",
       " ['then what', 'entonces qué'],\n",
       " ['they left', 'se fueron'],\n",
       " ['tom is ok', 'tom está bien'],\n",
       " ['tom is in', 'tom está dentro'],\n",
       " ['tom knows', 'tom sabe'],\n",
       " ['tom stood', 'tom se quedó'],\n",
       " ['tom tried', 'tomás lo intentó'],\n",
       " ['tom works', 'tomás trabaja'],\n",
       " ['tom s mad', 'tom está loco'],\n",
       " ['tom s sad', 'tom está triste'],\n",
       " ['wait here', 'espera aquí'],\n",
       " ['we can go', 'podemos ir'],\n",
       " ['we saw it', 'lo vimos'],\n",
       " ['well done', 'bien hecho'],\n",
       " ['what s up', 'qué hay'],\n",
       " ['who is he', 'quién es él'],\n",
       " ['who is it', 'quién es'],\n",
       " ['who stood', 'quién se quedó'],\n",
       " ['who s tom', 'quién es tom'],\n",
       " ['write tom', 'escribe a tom'],\n",
       " ['you start', 'tú empieza'],\n",
       " ['am i right', 'tengo razón'],\n",
       " ['are you ok', 'estás bien'],\n",
       " ['are you in', 'estás dentro'],\n",
       " ['ask around', 'pregunta por aquí'],\n",
       " ['be careful', 'ten cuidado'],\n",
       " ['be on time', 'llega a tiempo'],\n",
       " ['be on time', 'llegue a tiempo'],\n",
       " ['be patient', 'sea paciente'],\n",
       " ['be serious', 'sé serio'],\n",
       " ['can i come', 'puedo ir'],\n",
       " ['can i come', 'puedo venir'],\n",
       " ['can i help', 'puedo ayudar'],\n",
       " ['can i stay', 'me puedo quedar'],\n",
       " ['carry this', 'lleva esto'],\n",
       " ['come again', 'vuelve otra vez'],\n",
       " ['come alone', 'ven solo'],\n",
       " ['come early', 'ven temprano'],\n",
       " ['come early', 'venga temprano'],\n",
       " ['come on in', 'entre'],\n",
       " ['come on in', 'pase'],\n",
       " ['come to me', 'ven a mí'],\n",
       " ['come to us', 'ven a nosotros'],\n",
       " ['did tom go', 'fue tom'],\n",
       " ['eat slowly', 'come despacio'],\n",
       " ['get to bed', 'vete a la cama'],\n",
       " ['go on home', 'vete a casa'],\n",
       " ['go see tom', 've a ver a tom'],\n",
       " ['he ate out', 'él salió a comer'],\n",
       " ['he gave up', 'lo dejó'],\n",
       " ['he is here', 'él está aquí'],\n",
       " ['he is kind', 'él es amable'],\n",
       " ['he is tall', 'él es alto'],\n",
       " ['he made it', 'lo hizo él'],\n",
       " ['he made it', 'lo hizo'],\n",
       " ['he s lying', 'él está mintiendo'],\n",
       " ['he s smart', 'es inteligente'],\n",
       " ['he s smart', 'él es inteligente'],\n",
       " ['here he is', 'aquí está él'],\n",
       " ['here it is', 'aquí está'],\n",
       " ['here we go', 'aquí vamos'],\n",
       " ['how is tom', 'cómo está tom'],\n",
       " ['how s work', 'qué tal el trabajo'],\n",
       " ['how s work', 'cómo van las cosas en el trabajo'],\n",
       " ['hurry home', 'rápido a casa'],\n",
       " ['i am a man', 'soy un hombre'],\n",
       " ['i am a man', 'soy una persona'],\n",
       " ['i am happy', 'soy feliz'],\n",
       " ['i am happy', 'estoy feliz'],\n",
       " ['i am happy', 'yo estoy contento'],\n",
       " ['i am ready', 'estoy listo'],\n",
       " ['i can help', 'yo puedo ayudar'],\n",
       " ['i can read', 'sé leer'],\n",
       " ['i can sing', 'puedo cantar'],\n",
       " ['i can swim', 'sé nadar'],\n",
       " ['i eat here', 'como aquí'],\n",
       " ['i eat here', 'yo como aquí'],\n",
       " ['i eat meat', 'yo como carne'],\n",
       " ['i feel bad', 'me siento mal'],\n",
       " ['i feel old', 'me siento viejo'],\n",
       " ['i felt bad', 'me sentía mal'],\n",
       " ['i found it', 'lo encontré'],\n",
       " ['i found it', 'lo encontré'],\n",
       " ['i got lost', 'me perdí'],\n",
       " ['i guess so', 'lo supongo'],\n",
       " ['i hate tom', 'odio a tom'],\n",
       " ['i have one', 'tengo uno'],\n",
       " ['i have one', 'yo tengo uno'],\n",
       " ['i knew tom', 'conocí a tom'],\n",
       " ['i know tom', 'conozco a tom'],\n",
       " ['i know her', 'la conozco'],\n",
       " ['i know him', 'lo conozco'],\n",
       " ['i know now', 'ahora sé'],\n",
       " ['i know you', 'te conozco'],\n",
       " ['i know you', 'os conozco'],\n",
       " ['i know you', 'les conozco'],\n",
       " ['i know you', 'yo a usted le conozco'],\n",
       " ['i know you', 'yo a ustedes les conozco'],\n",
       " ['i like him', 'me gusta él'],\n",
       " ['i like him', 'él me gusta'],\n",
       " ['i like tea', 'me gusta el té'],\n",
       " ['i liked it', 'me gustó'],\n",
       " ['i love tom', 'lo amo a tomás'],\n",
       " ['i love him', 'yo lo amo'],\n",
       " ['i love him', 'lo amo'],\n",
       " ['i love you', 'te quiero'],\n",
       " ['i love you', 'te amo'],\n",
       " ['i love you', 'te amo'],\n",
       " ['i love you', 'os amo'],\n",
       " ['i miss him', 'lo extraño'],\n",
       " ['i must run', 'tengo que correr'],\n",
       " ['i need tom', 'necesito a tom'],\n",
       " ['i need ice', 'necesito hielo'],\n",
       " ['i ran home', 'me fui corriendo a casa'],\n",
       " ['i remember', 'me acuerdo'],\n",
       " ['i remember', 'yo me acuerdo'],\n",
       " ['i remember', 'yo recuerdo'],\n",
       " ['i remember', 'lo recuerdo'],\n",
       " ['i said yes', 'dije que sí'],\n",
       " ['i saw that', 'lo vi'],\n",
       " ['i saw that', 'vi eso'],\n",
       " ['i saw that', 'veía eso'],\n",
       " ['i see them', 'los veo'],\n",
       " ['i see them', 'las veo'],\n",
       " ['i think so', 'creo que sí'],\n",
       " ['i think so', 'eso creo'],\n",
       " ['i told tom', 'se lo dije a tom'],\n",
       " ['i told tom', 'se lo he dicho a tom'],\n",
       " ['i want tom', 'quiero a tom'],\n",
       " ['i want one', 'quiero uno'],\n",
       " ['i want one', 'quiero una'],\n",
       " ['i want one', 'quiero uno'],\n",
       " ['i want one', 'yo quiero uno'],\n",
       " ['i was last', 'fui el último'],\n",
       " ['i was last', 'era el último'],\n",
       " ['i was late', 'llegué tarde'],\n",
       " ['i was sick', 'yo estaba enfermo'],\n",
       " ['i was sick', 'yo estaba enferma'],\n",
       " ['i won t go', 'no voy a ir'],\n",
       " ['i work out', 'yo hago ejercicio'],\n",
       " ['i ll be ok', 'estaré bien'],\n",
       " ['i ll do it', 'lo haré yo'],\n",
       " ['i ll do it', 'lo haré'],\n",
       " ['i ll go in', 'voy a entrar'],\n",
       " ['i m better', 'yo soy mejor'],\n",
       " ['i m coming', 'ahí voy'],\n",
       " ['i m eating', 'estoy comiendo'],\n",
       " ['i m faster', 'yo soy más rápido'],\n",
       " ['i m hungry', 'ya tengo hambre'],\n",
       " ['i m trying', 'lo estoy intentando'],\n",
       " ['i ve eaten', 'he comido'],\n",
       " ['is tom big', 'es grande tom'],\n",
       " ['is tom fun', 'tom es divertido'],\n",
       " ['is tom hot', 'tiene calor tom'],\n",
       " ['is tom ill', 'tom está enfermo'],\n",
       " ['is tom mad', 'está loco tom'],\n",
       " ['is tom out', 'está fuera tom'],\n",
       " ['is he dead', 'está muerto'],\n",
       " ['is he tall', 'es alto'],\n",
       " ['is it good', 'está bueno'],\n",
       " ['is it here', 'es acá'],\n",
       " ['is it here', 'aquí'],\n",
       " ['is it here', 'está aquí'],\n",
       " ['is it safe', 'es seguro'],\n",
       " ['is it true', 'es verdad'],\n",
       " ['is that ok', 'vale eso'],\n",
       " ['is that ok', 'está bien eso'],\n",
       " ['is that it', 'eso es todo'],\n",
       " ['is that it', 'es ese'],\n",
       " ['is that so', 'acaso es así'],\n",
       " ['is that so', 'es así'],\n",
       " ['is this ok', 'esto es bueno'],\n",
       " ['is this it', 'eso es todo'],\n",
       " ['is this it', 'es este'],\n",
       " ['it happens', 'eso pasa'],\n",
       " ['it is cold', 'está frío'],\n",
       " ['it is mine', 'es mío'],\n",
       " ['it s tom s', 'es de tom'],\n",
       " ['it s alive', 'está vivo'],\n",
       " ['it s green', 'es verde'],\n",
       " ['it s green', 'está verde'],\n",
       " ['it s night', 'es de noche'],\n",
       " ['it s on me', 'es de parte mía'],\n",
       " ['it s ready', 'está listo'],\n",
       " ['it s right', 'vale'],\n",
       " ['it s right', 'está bien'],\n",
       " ['it s right', 'es correcto'],\n",
       " ['it s there', 'está ahí'],\n",
       " ['it s white', 'es blanco'],\n",
       " ['it s yours', 'es tuyo'],\n",
       " ['leave town', 'deja la ciudad'],\n",
       " ['leave town', 'sal de la ciudad'],\n",
       " ['let tom go', 'deja ir a tom'],\n",
       " ['let tom in', 'dejar entrar a tom'],\n",
       " ['let him go', 'deja que se vaya'],\n",
       " ['let me out', 'déjame salir'],\n",
       " ['let me see', 'déjame ver'],\n",
       " ['let me see', 'a ver'],\n",
       " ['look again', 'mira de nuevo'],\n",
       " ['look ahead', 'mira hacia adelante'],\n",
       " ['look there', 'mira allí'],\n",
       " ['no problem', 'no hay problema'],\n",
       " ['no problem', 'sin problemas'],\n",
       " ['no problem', 'ningún problema'],\n",
       " ['nobody ran', 'no corrió nadie'],\n",
       " ['nobody ran', 'nadie corrió'],\n",
       " ['say please', 'di por favor'],\n",
       " ['she is old', 'es vieja'],\n",
       " ['she smiled', 'sonrió'],\n",
       " ['she s busy', 'ella está ocupada'],\n",
       " ['she s nice', 'es guapa'],\n",
       " ['start here', 'empieza aquí'],\n",
       " ['start over', 'empieza de nuevo'],\n",
       " ['take a bus', 'toma un bus'],\n",
       " ['talk to me', 'habla conmigo'],\n",
       " ['that a boy', 'buen chico'],\n",
       " ['that works', 'eso funciona'],\n",
       " ['that ll do', 'con eso vale'],\n",
       " ['that ll do', 'eso me vale'],\n",
       " ['that s her', 'es ella'],\n",
       " ['that s his', 'eso le pertenece'],\n",
       " ['that s his', 'eso le pertenece a él'],\n",
       " ['that s new', 'es nuevo'],\n",
       " ['they re in', 'ellos están dentro'],\n",
       " ['they re in', 'ellas están dentro'],\n",
       " ['this is ok', 'esto está bien'],\n",
       " ['this is ok', 'esto está correcto'],\n",
       " ['this is it', 'hemos llegado'],\n",
       " ['this is it', 'este es el fin'],\n",
       " ['this is it', 'esto es todo'],\n",
       " ['this is it', 'éste es'],\n",
       " ['this works', 'esto funciona'],\n",
       " ['this works', 'esto trabaja'],\n",
       " ['this ll do', 'con éste vale'],\n",
       " ['tom agreed', 'tom estuvo de acuerdo'],\n",
       " ['tom called', 'tom llamó'],\n",
       " ['tom did it', 'tom lo hizo'],\n",
       " ['tom drinks', 'tom bebe'],\n",
       " ['tom drinks', 'tom toma'],\n",
       " ['tom forgot', 'a tom se le olvidó'],\n",
       " ['tom got up', 'tom se levantó'],\n",
       " ['tom helped', 'tom ayudó'],\n",
       " ['tom hit me', 'tom me golpeó'],\n",
       " ['tom is bad', 'tom es malo'],\n",
       " ['tom is big', 'tom es grande'],\n",
       " ['tom is fun', 'tom es divertido'],\n",
       " ['tom is ill', 'tom está malo'],\n",
       " ['tom is mad', 'tom está loco'],\n",
       " ['tom is new', 'tom es nuevo'],\n",
       " ['tom is old', 'tom es viejo'],\n",
       " ['tom is sad', 'tom está triste'],\n",
       " ['tom looked', 'tom miró'],\n",
       " ['tom saw it', 'tom lo vio'],\n",
       " ['tom saw me', 'tom me vio'],\n",
       " ['tom saw us', 'tom nos vio'],\n",
       " ['tom smiled', 'tom sonrió'],\n",
       " ['tom stayed', 'tom se quedó'],\n",
       " ['tom was ok', 'tom estaba bien'],\n",
       " ['tom s busy', 'tom está ocupado'],\n",
       " ['tom s dead', 'tom ha muerto'],\n",
       " ['tom s died', 'tom ha muerto'],\n",
       " ['tom s fast', 'tom es rápido'],\n",
       " ['tom s free', 'tom es libre'],\n",
       " ['tom s glad', 'tom está contento'],\n",
       " ['tom s gone', 'tom se ha ido'],\n",
       " ['tom s here', 'tom está aquí'],\n",
       " ['tom s home', 'tom está en casa'],\n",
       " ['tom s hurt', 'tom está herido'],\n",
       " ['tom s mean', 'tom es malo'],\n",
       " ['tom s safe', 'tom está seguro'],\n",
       " ['tom s sick', 'tom está enfermo'],\n",
       " ['tom s well', 'tom está bien'],\n",
       " ['was it fun', 'fue divertido'],\n",
       " ['was it fun', 'era divertido'],\n",
       " ['watch this', 'mira esto'],\n",
       " ['we are men', 'somos hombres'],\n",
       " ['we can pay', 'nosotros podemos pagar'],\n",
       " ['we can win', 'podemos ganar'],\n",
       " ['we like it', 'nos gusta'],\n",
       " ['we love it', 'nos encanta'],\n",
       " ['we made it', 'lo hicimos'],\n",
       " ['we must go', 'nos debemos ir'],\n",
       " ['we saw tom', 'vimos a tom'],\n",
       " ['we saw you', 'te vimos'],\n",
       " ['we want it', 'lo queremos'],\n",
       " ['we ll walk', 'nos vamos a caminar'],\n",
       " ['we re back', 'hemos vuelto'],\n",
       " ['we re back', 'estamos de vuelta'],\n",
       " ['we re cold', 'tenemos frío'],\n",
       " ['we re even', 'estamos a mano'],\n",
       " ['we re fine', 'estamos bien'],\n",
       " ['we re here', 'estamos acá'],\n",
       " ['we re home', 'estamos en casa'],\n",
       " ['what a day', 'pero qué día'],\n",
       " ['what s new', 'qué hay de nuevo'],\n",
       " ['where am i', 'dónde estoy'],\n",
       " ['where am i', 'en dónde estoy'],\n",
       " ['who is tom', 'quién es tom'],\n",
       " ['who stayed', 'quién se quedó'],\n",
       " ['who s here', 'quién está aquí'],\n",
       " ['who s next', 'quién da la vez'],\n",
       " ['who s that', 'quién es'],\n",
       " ['you can go', 'puedes irte'],\n",
       " ['you can go', 'puedes ir'],\n",
       " ['you can go', 'te puedes ir'],\n",
       " ['you may go', 'puedes irte'],\n",
       " ['you may go', 'pueden irse'],\n",
       " ['you may go', 'podéis ir'],\n",
       " ['you may go', 'podés irte'],\n",
       " ['you re bad', 'eres mala'],\n",
       " ['you re big', 'eres grande'],\n",
       " ['you re big', 'estás grande'],\n",
       " ['you re old', 'estás vieja'],\n",
       " ['you re sad', 'estás triste'],\n",
       " ['all is well', 'todo va bien'],\n",
       " ['all is well', 'todo está correcto'],\n",
       " ['anyone home', 'hay alguien en casa'],\n",
       " ['anyone home', 'alguien está en casa'],\n",
       " ['anyone hurt', 'alguien está herido'],\n",
       " ['are we done', 'hemos terminado'],\n",
       " ['are you tom', 'tú eres tom'],\n",
       " ['are you tom', 'es usted tom'],\n",
       " ['are you hot', 'tienes calor'],\n",
       " ['are you hot', 'tenéis calor'],\n",
       " ['are you mad', 'estás loco'],\n",
       " ['are you mad', 'estás enfadado'],\n",
       " ['are you mad', 'está usted loco'],\n",
       " ['are you new', 'eres nuevo'],\n",
       " ['are you new', 'eres nueva'],\n",
       " ['beer s good', 'la cerveza es buena'],\n",
       " ['can it wait', 'puede esperar'],\n",
       " ['can we talk', 'podemos hablar'],\n",
       " ['can you see', 'puedes ver'],\n",
       " ['can you see', 'podéis ver'],\n",
       " ['come see me', 'ven a verme'],\n",
       " ['come see me', 'venga a verme'],\n",
       " ['cook for me', 'cocina para mí'],\n",
       " ['count me in', 'cuenta conmigo'],\n",
       " ['count on it', 'cuenta con eso'],\n",
       " ['count on me', 'cuenta conmigo'],\n",
       " ['did tom die', 'ha muerto tom'],\n",
       " ['do as i say', 'haz lo que te digo'],\n",
       " ['don t do it', 'no lo hagas'],\n",
       " ['don t do it', 'no lo hagas'],\n",
       " ['don t do it', 'no lo haga'],\n",
       " ['don t go in', 'no entre usted'],\n",
       " ['don t leave', 'no te vayas'],\n",
       " ['get started', 'empieza'],\n",
       " ['go find tom', 've a encontrar a tom'],\n",
       " ['go find tom', 'vete a buscar a tom'],\n",
       " ['go for help', 've por ayuda'],\n",
       " ['go get help', 've a pedir ayuda'],\n",
       " ['go help tom', 've a ayudar a tom'],\n",
       " ['go home now', 'vete a casa ahora'],\n",
       " ['go meet tom', 've a ver a tom'],\n",
       " ['go that way', 've por ahí'],\n",
       " ['go that way', 've por allí'],\n",
       " ['go to sleep', 'vete a dormir'],\n",
       " ['go to sleep', 've a dormir'],\n",
       " ['go to sleep', 'vete a dormir'],\n",
       " ['he can come', 'él puede venir'],\n",
       " ['he can read', 'él sabe leer'],\n",
       " ['he can swim', 'él sabe nadar'],\n",
       " ['he found it', 'él lo encontró'],\n",
       " ['he has come', 'ha venido'],\n",
       " ['he has wine', 'tiene vino'],\n",
       " ['he is alone', 'él está solo'],\n",
       " ['he is drunk', 'él está borracho'],\n",
       " ['he is eight', 'él tiene ocho años'],\n",
       " ['he is happy', 'es feliz'],\n",
       " ['he is happy', 'él está feliz'],\n",
       " ['he is lying', 'él está mintiendo'],\n",
       " ['he is tired', 'él está cansado'],\n",
       " ['he is young', 'él es joven'],\n",
       " ['he likes me', 'él me quiere'],\n",
       " ['he stood up', 'él se levantó'],\n",
       " ['he was busy', 'él estaba ocupado'],\n",
       " ['he s not in', 'no está aquí'],\n",
       " ['he s not in', 'no está en casa'],\n",
       " ['he s not in', 'él no está en casa'],\n",
       " ['he s strong', 'él es fuerte'],\n",
       " ['he s stupid', 'él es estúpido'],\n",
       " ['here i come', 'ya estoy aquí'],\n",
       " ['here she is', 'aquí está ella'],\n",
       " ['here we are', 'aquí estamos'],\n",
       " ['here we are', 'aquí estamos'],\n",
       " ['how strange', 'qué raro'],\n",
       " ['how strange', 'qué raro'],\n",
       " ['i am better', 'estoy mejor'],\n",
       " ['i am better', 'soy mejor'],\n",
       " ['i am better', 'me encuentro mejor'],\n",
       " ['i am eating', 'estoy comiendo'],\n",
       " ['i am taller', 'yo soy más alto'],\n",
       " ['i bought it', 'lo he comprado'],\n",
       " ['i bought it', 'lo compré'],\n",
       " ['i came last', 'quedé último'],\n",
       " ['i came last', 'quedé en último lugar'],\n",
       " ['i came last', 'quedé última'],\n",
       " ['i can do it', 'puedo hacerlo'],\n",
       " ['i can t eat', 'no puedo comer'],\n",
       " ['i can t say', 'no lo puedo decir'],\n",
       " ['i can t say', 'no puedo decir'],\n",
       " ['i don t eat', 'no como'],\n",
       " ['i eat bread', 'como pan'],\n",
       " ['i eat fruit', 'como fruta'],\n",
       " ['i feel sick', 'me siento mal'],\n",
       " ['i felt cold', 'tenía frío'],\n",
       " ['i felt that', 'sentí eso'],\n",
       " ['i forgot it', 'lo olvidé'],\n",
       " ['i found you', 'ya te encontré'],\n",
       " ['i found you', 'te encontré'],\n",
       " ['i got a job', 'encontré un trabajo'],\n",
       " ['i had to go', 'tuve que ir'],\n",
       " ['i hate cats', 'odio los gatos'],\n",
       " ['i hate dogs', 'odio a los perros'],\n",
       " ['i hate dogs', 'odio los perros'],\n",
       " ['i hate milk', 'odio la leche'],\n",
       " ['i have time', 'tengo tiempo'],\n",
       " ['i have wine', 'tengo vino'],\n",
       " ['i heard you', 'te oí'],\n",
       " ['i heard you', 'te he oído'],\n",
       " ['i knew that', 'lo sabía'],\n",
       " ['i knew that', 'yo sabía eso'],\n",
       " ['i know that', 'yo sé eso'],\n",
       " ['i know them', 'los conozco'],\n",
       " ['i know this', 'esto lo sé'],\n",
       " ['i know this', 'conozco esto'],\n",
       " ['i know this', 'sé esto'],\n",
       " ['i like both', 'me gustan los dos'],\n",
       " ['i like dogs', 'me gustan los perros'],\n",
       " ['i like milk', 'me gusta la leche'],\n",
       " ['i like rice', 'me gusta el arroz'],\n",
       " ['i like snow', 'me gusta la nieve'],\n",
       " ['i like that', 'me gusta eso'],\n",
       " ['i like them', 'me gustan'],\n",
       " ['i like this', 'me gusta esto'],\n",
       " ['i like wine', 'me gusta el vino'],\n",
       " ['i liked tom', 'amaba a tom'],\n",
       " ['i live here', 'vivo aquí'],\n",
       " ['i live here', 'yo vivo aquí'],\n",
       " ['i love beer', 'me encanta la cerveza'],\n",
       " ['i love fish', 'me encanta el pescado'],\n",
       " ['i love golf', 'me encanta el golf'],\n",
       " ['i love life', 'amo la vida'],\n",
       " ['i love snow', 'me encanta la nieve'],\n",
       " ['i love snow', 'me gusta la nieve'],\n",
       " ['i love soup', 'me encanta la sopa'],\n",
       " ['i loved her', 'yo la amaba'],\n",
       " ['i loved her', 'la amaba'],\n",
       " ['i loved her', 'yo la quería'],\n",
       " ['i loved you', 'yo te quería'],\n",
       " ['i loved you', 'yo te quise'],\n",
       " ['i loved you', 'yo os quería'],\n",
       " ['i loved you', 'yo te amaba'],\n",
       " ['i loved you', 'yo os quise'],\n",
       " ['i loved you', 'yo os amaba'],\n",
       " ['i made that', 'yo hice eso'],\n",
       " ['i need help', 'necesito ayuda'],\n",
       " ['i need help', 'necesito ayuda'],\n",
       " ['i need mine', 'necesito el mío'],\n",
       " ['i need mine', 'necesito la mía'],\n",
       " ['i need them', 'los necesito'],\n",
       " ['i need this', 'necesito esto'],\n",
       " ['i need time', 'necesito tiempo'],\n",
       " ['i said stop', 'dije que alto'],\n",
       " ['i said that', 'yo dije eso'],\n",
       " ['i saw a dog', 'vi a un perro'],\n",
       " ['i saw a dog', 'vi un perro'],\n",
       " ['i saw a dog', 'yo vi un perro'],\n",
       " ['i should go', 'me debería ir'],\n",
       " ['i want mine', 'quiero el mío'],\n",
       " ['i want mine', 'yo quiero el mío'],\n",
       " ['i want mine', 'yo quiero la mía'],\n",
       " ['i want more', 'quiero más'],\n",
       " ['i want that', 'quiero eso'],\n",
       " ['i want them', 'los quiero'],\n",
       " ['i want them', 'las quiero'],\n",
       " ['i want this', 'quiero este'],\n",
       " ['i want this', 'quiero esto'],\n",
       " ['i was bored', 'estaba aburrido'],\n",
       " ['i was drunk', 'estaba borracho'],\n",
       " ['i was lucky', 'tuve suerte'],\n",
       " ['i was right', 'yo tenía razón'],\n",
       " ['i was tired', 'estaba cansado'],\n",
       " ['i was wrong', 'estaba equivocado'],\n",
       " ['i went home', 'me fui a casa'],\n",
       " ['i went too', 'yo también fui'],\n",
       " ['i will work', 'voy a trabajar'],\n",
       " ['i work here', 'trabajo aquí'],\n",
       " ['i m  too', 'yo también tengo  años'],\n",
       " ['i m a woman', 'soy una mujer'],\n",
       " ['i m a woman', 'soy mujer'],\n",
       " ['i m at home', 'estoy en casa'],\n",
       " ['i m at home', 'ya estoy en casa'],\n",
       " ['i m at home', 'estoy en la casa'],\n",
       " ['i m leaving', 'me voy'],\n",
       " ['i m married', 'estoy casado'],\n",
       " ['i m married', 'soy casado'],\n",
       " ['i m nervous', 'estoy nervioso'],\n",
       " ['i m not tom', 'no soy tom'],\n",
       " ['i m not old', 'no estoy viejo'],\n",
       " ['i m not sad', 'no estoy triste'],\n",
       " ['i m patient', 'soy paciente'],\n",
       " ['i m reading', 'estoy leyendo'],\n",
       " ['i m serious', 'lo digo en serio'],\n",
       " ['i m serious', 'hablo en serio'],\n",
       " ['i m so full', 'estoy tan lleno'],\n",
       " ['i m through', 'he terminado'],\n",
       " ['i m waiting', 'estoy esperando'],\n",
       " ['i m working', 'estoy trabajando'],\n",
       " ['is tom dead', 'tom está muerto'],\n",
       " ['is tom good', 'tom es bueno'],\n",
       " ['is tom here', 'está aquí tom'],\n",
       " ['is tom here', 'está tom'],\n",
       " ['is tom home', 'tom está en casa'],\n",
       " ['is tom home', 'está tom en casa'],\n",
       " ['is tom hurt', 'tom está herido'],\n",
       " ['is he right', 'está él bien'],\n",
       " ['is he right', 'está en lo cierto'],\n",
       " ['is he right', 'es lo que él dice'],\n",
       " ['is it there', 'está ahí'],\n",
       " ['is it to go', 'para llevar'],\n",
       " ['is it yours', 'es vuestro'],\n",
       " ['is that tom', 'es ese tom'],\n",
       " ['is that all', 'es todo'],\n",
       " ['is that new', 'es eso nuevo'],\n",
       " ['is that you', 'eres tú'],\n",
       " ['is that you', 'es usted'],\n",
       " ['is this new', 'esto es nuevo'],\n",
       " ['it can t be', 'no puede ser'],\n",
       " ['it cost', 'costó  dólares'],\n",
       " ['it happened', 'pasó'],\n",
       " ['it happened', 'eso sucedió'],\n",
       " ['it is there', 'está ahí'],\n",
       " ['it may snow', 'puede que nieve'],\n",
       " ['it may snow', 'es posible que nieve'],\n",
       " ['it was cool', 'estuvo padre'],\n",
       " ['it was easy', 'fue fácil'],\n",
       " ['it was easy', 'era fácil'],\n",
       " ['it s  yen', 'son  yenes'],\n",
       " ['it s monday', 'es lunes'],\n",
       " ['it s a song', 'esto es una canción'],\n",
       " ['it s all ok', 'todo bien'],\n",
       " ['it s boring', 'esto es aburrido'],\n",
       " ['it s boring', 'es aburrido'],\n",
       " ['it s broken', 'está roto'],\n",
       " ['it s my job', 'es mi trabajo'],\n",
       " ['it s not us', 'no somos nosotros'],\n",
       " ['it s secret', 'es secreto'],\n",
       " ['just say no', 'solo di que no'],\n",
       " ['keep trying', 'sigue intentando'],\n",
       " ['let me help', 'déjame ayudarte'],\n",
       " ['let me help', 'déjame ayudar'],\n",
       " ['let me live', 'déjame vivir'],\n",
       " ['look at tom', 'mira a tom'],\n",
       " ['make a list', 'haz una lista'],\n",
       " ['many thanks', 'muchas gracias'],\n",
       " ['no means no', 'no significa no'],\n",
       " ['no means no', 'no significa no'],\n",
       " ['no one came', 'nadie vino'],\n",
       " ['no one came', 'no vino nadie'],\n",
       " ['no one died', 'nadie murió'],\n",
       " ['no one died', 'no murió nadie'],\n",
       " ['nobody came', 'nadie vino'],\n",
       " ['nobody came', 'no vino nadie'],\n",
       " ['nobody came', 'no ha venido nadie'],\n",
       " ['nobody died', 'nadie murió'],\n",
       " ['nobody died', 'no murió nadie'],\n",
       " ['nobody knew', 'nadie lo sabía'],\n",
       " ['now i m sad', 'ahora estoy triste'],\n",
       " ['now move on', 'ahora sigue'],\n",
       " ['ok i agree', 'bueno estoy de acuerdo'],\n",
       " ['one is blue', 'uno es azul'],\n",
       " ['one is blue', 'una es azul'],\n",
       " ['please wait', 'espera un momento'],\n",
       " ['say nothing', 'no digas nada'],\n",
       " ['shall we go', 'nos vamos'],\n",
       " ['she hit him', 'ella le golpeó'],\n",
       " ['she is kind', 'ella es amable'],\n",
       " ['should i go', 'debería ir'],\n",
       " ['start again', 'empieza de nuevo'],\n",
       " ['start again', 'empieza otra vez'],\n",
       " ['stop crying', 'deja de llorar'],\n",
       " ['talk to tom', 'habla con tom'],\n",
       " ['tea please', 'un té por favor'],\n",
       " ['that helped', 'eso ayudó'],\n",
       " ['that is all', 'ya está'],\n",
       " ['that is all', 'es todo'],\n",
       " ['that s easy', 'eso es fácil'],\n",
       " ['that s fine', 'está bien'],\n",
       " ['that s good', 'eso es bueno'],\n",
       " ['that s good', 'eso está bien'],\n",
       " ['that s life', 'esa es la vida'],\n",
       " ['that s life', 'así es la vida'],\n",
       " ['that s mine', 'eso es mío'],\n",
       " ['that s nice', 'es agradable'],\n",
       " ['that s nice', 'está bien'],\n",
       " ['that s nice', 'eso es bueno'],\n",
       " ['that s over', 'ya ha pasado'],\n",
       " ['that s them', 'ahí están'],\n",
       " ['that s them', 'son ellos'],\n",
       " ['that s true', 'eso es cierto'],\n",
       " ['that s true', 'eso es verdad'],\n",
       " ['there it is', 'allá está'],\n",
       " ['there s tom', 'ahí está tom'],\n",
       " ['they did it', 'lo hicieron'],\n",
       " ['they did it', 'lo hicieron ellos'],\n",
       " ['they did it', 'ellos lo hicieron'],\n",
       " ['they re new', 'son nuevos'],\n",
       " ['think again', 'piensa de nuevo'],\n",
       " ['this is tom', 'este es tom'],\n",
       " ['this is bad', 'eso es malo'],\n",
       " ['this is big', 'esto es grande'],\n",
       " ['this is his', 'esto es de él'],\n",
       " ['tom arrived', 'tom llegó'],\n",
       " ['tom ate out', 'tom salió a comer'],\n",
       " ['tom decided', 'tom decidió'],\n",
       " ['tom is busy', 'tom está ocupado'],\n",
       " ['tom is dead', 'tom está muerto'],\n",
       " ['tom is dead', 'tom ha muerto'],\n",
       " ['tom is full', 'tom está lleno'],\n",
       " ['tom is full', 'tom está satisfecho'],\n",
       " ['tom is here', 'tom está aquí'],\n",
       " ['tom is hurt', 'tom está herido'],\n",
       " ['tom is nice', 'tom es amable'],\n",
       " ['tom is poor', 'tomás es pobre'],\n",
       " ['tom is sick', 'tom está enfermo'],\n",
       " ['tom is tall', 'tom es alto'],\n",
       " ['tom refused', 'tom se negó'],\n",
       " ['tom was old', 'tomás era mayor'],\n",
       " ['tom was sad', 'tom estaba triste'],\n",
       " ['tom s alive', 'tom está vivo'],\n",
       " ['tom s alone', 'tom está solo'],\n",
       " ['tom s bored', 'tom está aburrido'],\n",
       " ['tom s crazy', 'tom es loco'],\n",
       " ['tom s drunk', 'tom está borracho'],\n",
       " ['tom s early', 'tom llega temprano'],\n",
       " ['tom s lying', 'tom está mintiendo'],\n",
       " ['tom s right', 'tom tiene razón'],\n",
       " ['tom s young', 'tom es joven'],\n",
       " ['wait for me', 'espera por mí'],\n",
       " ['wait for us', 'espera por nosotros'],\n",
       " ['was i wrong', 'estaba equivocado'],\n",
       " ['was it cold', 'hacía frío'],\n",
       " ['was it good', 'estuvo bueno'],\n",
       " ['we are even', 'estamos a mano'],\n",
       " ['we are here', 'estamos aquí'],\n",
       " ['we can help', 'podemos ayudar'],\n",
       " ['we can help', 'nosotros podemos ayudar'],\n",
       " ['we can talk', 'podemos hablar'],\n",
       " ['we can wait', 'podemos esperar'],\n",
       " ['we know why', 'sabemos por qué'],\n",
       " ['we like tom', 'tom nos gusta'],\n",
       " ['we like tom', 'queremos a tom'],\n",
       " ['we love you', 'te queremos'],\n",
       " ['we love you', 'os queremos'],\n",
       " ['we must run', 'tenemos que correr'],\n",
       " ['we need you', 'te necesitamos'],\n",
       " ['we want tom', 'queremos a tom'],\n",
       " ['we want one', 'queremos uno de esos'],\n",
       " ['we re broke', 'estamos sin un duro'],\n",
       " ['we re going', 'nos vamos'],\n",
       " ['we re going', 'vamos a ir'],\n",
       " ['we re going', 'nosotros vamos a ir'],\n",
       " ['we re happy', 'somos felices'],\n",
       " ['we re right', 'tenemos razón'],\n",
       " ['we re young', 'somos jóvenes'],\n",
       " ['what a pain', 'qué dolor'],\n",
       " ['what a team', 'qué equipo'],\n",
       " ['what is new', 'qué hay de nuevo'],\n",
       " ['what s good', 'qué está bueno'],\n",
       " ['what s good', 'qué está bien'],\n",
       " ['what s this', 'qué es esto'],\n",
       " ['where is he', 'dónde está él'],\n",
       " ['where s tom', 'dónde está tom'],\n",
       " ['who are you', 'quién sos'],\n",
       " ['who are you', 'quién es usted'],\n",
       " ['who is next', 'quién es el siguiente'],\n",
       " ['who is that', 'quién es'],\n",
       " ['who said it', 'quién lo dijo'],\n",
       " ['who saw you', 'quién te vio'],\n",
       " ['who ll come', 'quién viene'],\n",
       " ['who ll cook', 'quién va a cocinar'],\n",
       " ['who s first', 'a quién le toca'],\n",
       " ['who s first', 'quién va primero'],\n",
       " ['who s first', 'quién es el primero'],\n",
       " ['who s going', 'quién va'],\n",
       " ['who s going', 'quién va a ir'],\n",
       " ['who s there', 'quién está ahí'],\n",
       " ['whose is it', 'de quién es'],\n",
       " ['why is that', 'por qué es eso'],\n",
       " ['why is that', 'por qué pasa eso'],\n",
       " ['why is this', 'a qué viene esto'],\n",
       " ['will you go', 'vas a ir'],\n",
       " ['will you go', 'va a ir'],\n",
       " ['yes i know', 'sí lo sé'],\n",
       " ['you are big', 'sos grande'],\n",
       " ['you know me', 'tú me conoces'],\n",
       " ['you know me', 'me conoces'],\n",
       " ['you know me', 'ya me conoces'],\n",
       " ['you made it', 'lo has hecho'],\n",
       " ['you need it', 'usted lo necesita'],\n",
       " ['you need it', 'lo necesitas'],\n",
       " ['you need us', 'nos necesitas'],\n",
       " ['you said it', 'así exactamente así'],\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cbaa67546e939414b5752e0a95c0078",
     "grade": false,
     "grade_id": "cell-c9cb3ec23bbe5c66",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "`input_lang` and `output_lang` are helper objects that contain important information about the languages loaded, and also dictionaries to map between words and indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df9f9b4ebfc127fa4f76a0f17acde741",
     "grade": false,
     "grade_id": "cell-06fb5b83929ba750",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdab8e48137b1678d343fc9c8b529a8f",
     "grade": false,
     "grade_id": "cell-710f5b42e5f82f03",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64578e01bbd6c020a26648947532977c",
     "grade": false,
     "grade_id": "cell-062c251db2d72892",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index['great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3a0c2e700574be1e021bf516da051fc",
     "grade": false,
     "grade_id": "cell-2bcfc45667215f16",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.index2word[702]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9e3f0543a9c1e7110ebac1317a86807",
     "grade": false,
     "grade_id": "cell-7130ad219189a0d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Finally, we also loaded some variables that define indexes for the three special word tokens we'll add to the sentences:\n",
    "- `PAD`: Padding;\n",
    "- `SOS`: Start of sentence;\n",
    "- `EOS`: End of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d458678d06ea2a89c33b3aee6e3248d4",
     "grade": false,
     "grade_id": "cell-08a85ba00b002bf5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16d10a92964cc2c62094d56eec31780a",
     "grade": false,
     "grade_id": "cell-9d07489bcff74552",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOS_word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79ce628f7163f1464f825ce1d81ce472",
     "grade": false,
     "grade_id": "cell-332b49fe883bd8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_word_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "653133d19854fcb6ecaf32dac1a69ff6",
     "grade": false,
     "grade_id": "cell-51d03d46a4730112",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2193bb0434c4d8f7009e6079b045023a",
     "grade": false,
     "grade_id": "cell-39d421f43d0c02c4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We'll pre-process the data in a similar way to task 1. The following function transforms a sentence into a tensor by changing each word into its corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fe3f7938e5256adb6c8e2b90d944781",
     "grade": false,
     "grade_id": "cell-2a548cd9fdb03d8f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sentence2tensor(lang, sentence):\n",
    "    return torch.tensor([lang.word2index[word] for word in sentence.split(' ')], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d4fdd9429729e29d70c46fcccd2d89f",
     "grade": false,
     "grade_id": "cell-9a0498b4a61bc45e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([107, 121,  60, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2tensor(input_lang, 'this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "243a3d2e48c38b80f1efba354a165cef",
     "grade": false,
     "grade_id": "cell-17aa1999bb0519d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.index2word[512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8110be2912e9ba135e686572c43a6c2",
     "grade": false,
     "grade_id": "cell-746bafddcbfd9aba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We also want to pad the sentences, so that all have equal length - allowing us to batch several sentences together and speed up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "446909d1539c0215ff184090fca8d428",
     "grade": false,
     "grade_id": "cell-4bb35eab7404cf63",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "def pad_all_sequences(sequences, padding_value, pad_on_the_left=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        sequences        - List of 1-D LongTensor elements of variable length, each tensor representing one sequence.\n",
    "        padding_value    - Integer value, with which to pad the sequences.\n",
    "        pad_on_the_left  - bool. If True, pad on the left-hand-side instead of right-hand-side.\n",
    "    Returns:\n",
    "        Tensor of shape (nbr_sequences, max_len), where max_len is the length of the padded sequences. nbr_sequences is the number of sequences provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pad_on_the_left:\n",
    "        # Flip each sequence along its one and only dimension (dim=0)\n",
    "        sequences = [torch.flip(seq_tensor, [0]) for seq_tensor in sequences]\n",
    "        \n",
    "    tensor_of_padded_seqs = nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=padding_value)\n",
    "    \n",
    "    if pad_on_the_left:\n",
    "        # Flip sequences back, along the sequential dimension (now dim=1)\n",
    "        tensor_of_padded_seqs = torch.flip(tensor_of_padded_seqs, [1])\n",
    "        \n",
    "\n",
    "    return tensor_of_padded_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "054b729d4c2a7240df5e841bf7409541",
     "grade": false,
     "grade_id": "cell-648a50a17d0269e2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that the function `pad_all_sequences` takes an argument named `pad_on_the_left`, which if set to `True`, pads the sequences on the left, instead of the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7f9d8c86eb39a3b8ff3bc5b8caa08a1",
     "grade": false,
     "grade_id": "cell-d351e9c8c79ee5df",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding:\n",
      "tensor([107, 121,  60, 702, 512])\n",
      "tensor([107,  49])\n",
      "tensor([778, 354, 512])\n",
      "\n",
      "After padding:\n",
      "tensor([107, 121,  60, 702, 512])\n",
      "tensor([107,  49,   0,   0,   0])\n",
      "tensor([778, 354, 512,   0,   0])\n",
      "\n",
      "After padding (on the left):\n",
      "tensor([107, 121,  60, 702, 512])\n",
      "tensor([  0,   0,   0, 107,  49])\n",
      "tensor([  0,   0, 778, 354, 512])\n"
     ]
    }
   ],
   "source": [
    "test_sentences = ['this is a great test', 'this too', 'yet another test']\n",
    "test_sequences = [sentence2tensor(input_lang, s) for s in test_sentences]\n",
    "print('Before padding:')\n",
    "for s in test_sequences:\n",
    "    print(s)\n",
    "    \n",
    "print('\\nAfter padding:')\n",
    "for s in pad_all_sequences(test_sequences, PAD_word_idx):\n",
    "    print(s)\n",
    "    \n",
    "print('\\nAfter padding (on the left):')\n",
    "for s in pad_all_sequences(test_sequences, PAD_word_idx, pad_on_the_left=True):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f455354ccfc0a49bb7d94e8c32b3819",
     "grade": false,
     "grade_id": "cell-eeac94c3ecfcc5e8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "Think about the encoder-decoder architecture commonly used for translation. In this context, why would we want to pad some sentences on the left and some on the right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72ae5ad22e2f22b4d9ab00d11e3210a7",
     "grade": true,
     "grade_id": "cell-e1459474d3e61f00",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** Because we want the inputs to the encoder to be padded on the left and the ground truth to the decoder should be padded on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f09b79e8196a1032081ee6840e604cb8",
     "grade": false,
     "grade_id": "cell-4473215afd0827d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we use `sentence2tensor` and `pad_all_sequences` to transform the `pairs` object into input and output tensors of word indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f412e8aca812caacb0af72a18f40332",
     "grade": false,
     "grade_id": "cell-535e46dd571b9284",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Separate input and target sentences from pairs\n",
    "input_sentences, target_sentences = zip(*pairs)\n",
    "\n",
    "# Create tensors, appending the <SOS> and <EOS> words to the target sequences.\n",
    "input_seq_tensors = [torch.tensor([input_lang.word2index[word] for word in sentence.split(' ')], \n",
    "                                  dtype=torch.long) \n",
    "                     for sentence in input_sentences]\n",
    "target_seq_tensors = [torch.tensor([SOS_word_idx] + [output_lang.word2index[word] for word in sentence.split(' ')] + [EOS_word_idx], \n",
    "                                   dtype=torch.long) \n",
    "                      for sentence in target_sentences]\n",
    "\n",
    "# Pad all sequences to equal length\n",
    "input_seq_tensors = pad_all_sequences(input_seq_tensors, PAD_word_idx, pad_on_the_left=True)\n",
    "target_seq_tensors = pad_all_sequences(target_seq_tensors, PAD_word_idx, pad_on_the_left=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e4490be9d0d4ddb0e708c41b0039ee6",
     "grade": false,
     "grade_id": "cell-c6938740fc6cf9db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that we're adding the `SOS` token to the start of all the target sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c577ca87b1c323f98429d21eb03c1da8",
     "grade": false,
     "grade_id": "cell-9b67db79adeb75d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33941, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d632a2b84fae850bc98a39c96b1d9cc8",
     "grade": false,
     "grade_id": "cell-a68000a248c4d4f7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33941, 11])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2668f104b3f8683cfeb922c90d1b1168",
     "grade": false,
     "grade_id": "cell-5fcb1a036ccf47fc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Using these tensors, we create a dataset and split it into train/val/test as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b77be122f6731d3c14d60683d8b0039c",
     "grade": false,
     "grade_id": "cell-782a05ee9fec69cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 17, 243, 109,  ...,   0,   0,   0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(input_seq_tensors, target_seq_tensors)\n",
    "\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "n_samples = len(dataset)\n",
    "n_val_samples = int(n_samples*val_ratio)\n",
    "n_test_samples = int(n_samples*test_ratio)\n",
    "n_train_samples = n_samples-n_val_samples-n_test_samples\n",
    "\n",
    "# Fix RNG seed\n",
    "old_state = torch.get_rng_state()\n",
    "torch.manual_seed(0)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [n_train_samples, n_val_samples, n_test_samples])\n",
    "torch.set_rng_state(old_state)\n",
    "print(old_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0df47891586ccab73dc10b95b21a33e2",
     "grade": false,
     "grade_id": "cell-5554838bcc3faced",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   0,   0,   0,   0,   0, 113, 109, 174]),\n",
       " tensor([  1, 389, 245,   2,   0,   0,   0,   0,   0,   0,   0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da50cc62be492f949b10d8587783b572",
     "grade": false,
     "grade_id": "cell-d1ffc03b003a1689",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Defining the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de0abd99fef7dbbd1ecbd385d0a82deb",
     "grade": false,
     "grade_id": "cell-ff83666a724761f0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As stated before, we'll tackle this translation task with an encoder-decoder architecture. In this section, you will define the `Encoder` and `Decoder` classes, and also the `Translator` class, that combines the other two to translate a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2b67acab17f1e6106ad90daee6b484e",
     "grade": false,
     "grade_id": "cell-957262dc380f1c7c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02de08dc94e23ef43bbba5b7f5f20d1d",
     "grade": false,
     "grade_id": "cell-db83c03e65ea6f71",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 2.3.1 Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96da9b98f01ca49f8deafe1bf0b7496d",
     "grade": false,
     "grade_id": "cell-80c4afb2321f429a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will start with the `Encoder` class. Its `forward` method should take as input a batch of tensors of word indexes and perform the following steps:\n",
    "\n",
    "- Embed the input tensors using the [`Embedding`](https://pytorch.org/docs/stable/nn.html#embedding) PyTorch layer.\n",
    "- Feed the embedded tensors into a multi-layer [`GRU` module](https://pytorch.org/docs/stable/nn.html#gru).\n",
    "- Output the hidden states of all GRU layers at the last time-step of the sequence (i.e. for the last word).\n",
    "\n",
    "*Tips*:\n",
    "- Read the entire documentation for both the [`Embedding`](https://pytorch.org/docs/stable/nn.html#embedding) and the [`GRU`](https://pytorch.org/docs/stable/nn.html#gru) layers.\n",
    "- Don't be confused: in task 1, when predicting nationalities, we created a module with a `forward` method that should be called for each element in the input sequence; *this is not the case for task 2*. Here we want the `forward` method of `Encoder` to run in the entire sequence with one call.\n",
    "- The `forward` method of the `GRU` module can be run in the entire sequence with one call (but you already know this, since you followed the first tip we mentioned 😁). Also, the `GRU` constructor has an argument named `batch_first`...\n",
    "- Initialize the hidden state of the `GRU`s to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53a164d71aafd1abc3004c7b86d6adfa",
     "grade": true,
     "grade_id": "cell-34c7a1017392b6bc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_size     - Number of unique word indexes in the input language (i.e. input_lang.n_words)\n",
    "            embedding_size - Dimensionality of the space the input tensors will be embedded before going into the\n",
    "                             recurrent unit.\n",
    "            hidden_size    - Dimensionality of the hidden vector in the GRUs.\n",
    "            num_layers     - Number of layers in the multi-layer GRU unit.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Runs the RNN encoder.\n",
    "        Inputs:\n",
    "            x              - Input sequence of word indexes. \n",
    "                             LongTensor, shape (batch_size, seq_len).\n",
    "        Returns:\n",
    "            new_h          - Hidden state at current time-step for all layers at the final sequence position.\n",
    "                             FloatTensor, shape (num_layers, batch_size, hidden_size).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        ex = self.embedding(x)\n",
    "        h = torch.zeros(3, x.shape[0], self.hidden_size).to(device)\n",
    "        _, new_h = self.gru(ex, h)\n",
    "        \n",
    "        return new_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bf289fc9b82a4d607e234c9b348e98a",
     "grade": false,
     "grade_id": "cell-ae42248d6749eff6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the following cell to test whether the shape of your outputs are correct. Note that this *only* checks the shapes, not the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "823396af31ee17eca7702fab6924b115",
     "grade": false,
     "grade_id": "cell-08639295de373894",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed. \n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 32\n",
    "test_num_layers = 3\n",
    "\n",
    "# Create encoder\n",
    "test_encoder = Encoder(input_size=input_lang.n_words, embedding_size=30, hidden_size=50, num_layers=test_num_layers)\n",
    "test_encoder.to(device)\n",
    "\n",
    "# Create dummy input\n",
    "test_x = torch.zeros(test_batch_size, 10, dtype=torch.long, device=device)\n",
    "\n",
    "# Forward-prop through the encoder\n",
    "test_new_h = test_encoder(test_x)\n",
    "\n",
    "# Test the shape of the output\n",
    "err_str = '`test_new_h` has incorrect dimensions. Dimension is {}, but should\\'ve been {}'\n",
    "correct_dimension = (test_num_layers, test_batch_size, test_encoder.hidden_size)\n",
    "assert test_new_h.shape == correct_dimension, err_str.format(tuple(test_new_h.shape), correct_dimension)\n",
    "print('Test passed. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84926f90db7db663adeb3a19680d35e1",
     "grade": false,
     "grade_id": "cell-59960950d507a5b7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 2.3.2 Decoder\n",
    "\n",
    "Now we move to the `Decoder` class. \n",
    "\n",
    "Its `forward` method takes the hidden state output from the `Encoder` as input, and predicts the word indexes corresponding to the translated sentence. Furthermore, since we will train our translator using teacher-forcing, this method also takes as input a sequence of word indexes corresponding to the ground-truth output sentence. \n",
    "\n",
    "The following steps need to be performed by the `forward` method:\n",
    "\n",
    "- Embed the ground-truth output sequence using an `Embedding` layer.\n",
    "- Feed the embedded sequence to a multi-layer `GRU` module.\n",
    "- Pass the computed hidden states of the `GRU` module at each time-step through a linear layer\n",
    "- Pass the outputs of the linear layer at each time-step through a `LogSoftmax` layer.\n",
    "\n",
    "The first output of this method is then a sequence numbers representing the probability mass functions over the possible output indexes for each time-step. The second output should be the hidden-states for all layers of the `GRU`s , for the last time-step of the sequence (i.e. for the last word index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06b2e266d0915396d0d719ec076f18fd",
     "grade": true,
     "grade_id": "cell-8602e5addd641b49",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, num_layers):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            embedding_size - Dimensionality of the space the input tensors will be embedded before going into the\n",
    "                             recurrent unit.\n",
    "            hidden_size    - Dimensionality of the hidden vector in the GRUs.\n",
    "            output_size    - Number of unique word indexes in the output language (i.e. output_lang.n_words)\n",
    "            num_layers     - Number of layers in the multi-layer GRU unit.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.LogSoftmax(dim=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x             - Sequence of word indexes corresponding to ground-truth output sentence. \n",
    "                            LongTensor, shape (batch_size, seq_len).\n",
    "            h             - Previous state (output from Encoder object). \n",
    "                            FloatTensor, shape (num_layers, batch_size, hidden_size).\n",
    "\n",
    "        Outputs:\n",
    "            out           - Output sequence of predicted distributions of target words.\n",
    "                            FloatTensor, shape (batch_size, seq_len, output_size).\n",
    "            new_h         - Hidden state at current time-step.\n",
    "                            FloatTensor, shape (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        ex = self.embedding(x)\n",
    "        y, new_h = self.gru(ex, h)\n",
    "        out = self.output_layer(y)\n",
    "\n",
    "        return out, new_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08647fa8ab35680eac0d5e10fc1efac0",
     "grade": false,
     "grade_id": "cell-4eed24b8e8f0279c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the following cell to both test the shapes of your outputs and also that the predicted distributions sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24c084d0ca2200027df6b4ef16a7798d",
     "grade": false,
     "grade_id": "cell-768c00536daaf170",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "test_batch_size = 6\n",
    "test_seq_len = 7\n",
    "\n",
    "# Create encoder\n",
    "test_decoder = Decoder(embedding_size=300, \n",
    "                       hidden_size=30, \n",
    "                       output_size=output_lang.n_words, \n",
    "                       num_layers=3)\n",
    "test_decoder.to(device)\n",
    "\n",
    "# Create dummy input and hidden state\n",
    "test_x = torch.ones(test_batch_size, test_seq_len, dtype=torch.long, device=device)\n",
    "test_h = torch.ones(test_decoder.num_layers, test_batch_size, test_decoder.hidden_size, device=device)\n",
    "\n",
    "# Forward-prop through the decoder\n",
    "out, test_new_h = test_decoder(test_x, test_h)\n",
    "\n",
    "# Does the new hidden state have the correct shape?\n",
    "err_msg = '{} has incorrect dimensions. Dimension is {}, but should\\'ve been {}'\n",
    "correct_shape = (test_decoder.num_layers, test_batch_size, test_decoder.hidden_size)\n",
    "assert test_new_h.shape == correct_shape, err_msg.format('`test_new_h`', tuple(test_new_h.shape), correct_shape)\n",
    "\n",
    "# Does the output have the correct shape?\n",
    "correct_shape = (test_batch_size, test_seq_len, output_lang.n_words)\n",
    "assert out.shape == correct_shape, err_msg.format('`out`', tuple(out.shape), correct_shape)\n",
    "\n",
    "# Do the predictions sum to 1?\n",
    "test_pred_sums = torch.sum(out.exp(), dim=2).detach().cpu().numpy()\n",
    "err_msg = 'Predictions do not sum to 1:\\n {}'.format(test_pred_sums)\n",
    "assert np.allclose(test_pred_sums, np.ones_like(test_pred_sums)),  err_msg\n",
    "\n",
    "print('Test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b7c040cc971a1f5468cf40d76fac9bf",
     "grade": false,
     "grade_id": "cell-aade27372bb6c7ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 2.3.4 Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "701cbd99222d97de73dc372d76583684",
     "grade": false,
     "grade_id": "cell-aeb3fcebf5a4cb1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that we defined the `Encoder` and the `Decoder` classes, we're ready to define the full model that connects these two together, the `Translator` class.\n",
    "\n",
    "This class has two methods, `forward` and `forward_no_teacher`. \n",
    "\n",
    "The first one is the one you will implement, which takes as input a sequence of word indexes corresponding to the input sentence. This sequence is fed to the `Translator`'s encoder, which outputs its last hidden state. Finally, this hidden state is then fed to the `Translator`'s decoder, together with the ground-truth word indexes corresponding to the ground-truth output sentence, resulting in the predicted word distributions for each position. This is the method we will use to compute predictions during training.\n",
    "\n",
    "The second method, `forward_no_teacher`, is already implemented for you. This method performs the same steps as outlined above, but this time without using the ground-truth output sequence for teacher forcing. Instead, the output of the decoder at time-step $t$ is fed to itself at time-step $t+1$ (instead of the ground-truth word index for this time-step). We will use this method for evaluating the final quality of our translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0648d8d134021013d99dbe80bda44d6",
     "grade": true,
     "grade_id": "cell-4c72b777d53ebc3c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Translator(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_size     - Number of unique word indexes in the input language (i.e. input_lang.n_words)\n",
    "            embedding_size - Dimensionality of the space the input tensors will be embedded before going into the\n",
    "                             recurrent unit.\n",
    "            hidden_size    - Dimensionality of the hidden vector in the GRUs.\n",
    "            output_size    - Number of unique word indexes in the output language (i.e. output_lang.n_words)\n",
    "            num_layers     - Number of layers in the multi-layer GRU unit.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        self.encoder = Encoder(input_size, embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = Decoder(embedding_size, hidden_size, output_size, num_layers)\n",
    "                \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x                - Sequence of word indexes corresponding to input sentence. \n",
    "                               LongTensor, shape (batch_size, input_seq_len).\n",
    "            y                - Sequence of word indexes corresponding to ground-truth output sentence.\n",
    "                               LongTensor, shape (batch_size, output_seq_len).\n",
    "\n",
    "        Outputs:\n",
    "            decoder_outputs  - Output sequence of predicted distributions of target words.\n",
    "                               FloatTensor, shape (batch_size, output_seq_len, output_size).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        h = self.encoder(x)\n",
    "        decoder_outputs, h = self.decoder(y, h)\n",
    "        \n",
    "        return decoder_outputs    \n",
    "    \n",
    "    def forward_no_teacher(self, x, max_len=10):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Encode input sentence. Shape: (num_layers, batch_size, hidden_size)\n",
    "            last_hidden_encoder = self.encoder(x)\n",
    "\n",
    "            # Initialize tensor for sentence that will be generated\n",
    "            generated_sentence = torch.zeros(1, 0, dtype=torch.long, device=device)\n",
    "\n",
    "            # Initialize input (SOS) and hidden state (output hidden state of encoder) for the decoder\n",
    "            x = torch.zeros(1, 1, dtype=torch.long, device=device)*SOS_word_idx\n",
    "            h = last_hidden_encoder        \n",
    "            \n",
    "            for i in range(max_len):\n",
    "                \n",
    "                # Compute output and new hidden state\n",
    "                out, h = self.decoder(x, h)\n",
    "                \n",
    "                # Choose the most probable word in the predicted pmf\n",
    "                x = out.argmax(dim=2)\n",
    "                \n",
    "                # Add this word to the generated sentence\n",
    "                generated_sentence = torch.cat([generated_sentence, x], dim=1)\n",
    "                \n",
    "                # Stop if generated word is EOS\n",
    "                if x.item() == EOS_word_idx:\n",
    "                    break\n",
    "\n",
    "            return generated_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ebf354aa97984a408f108ba9d2bf1de",
     "grade": false,
     "grade_id": "cell-dc2c9633f7affdf4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the following cell to both test the shapes of your outputs and also that the predicted distributions sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bc86dc737005063ea8dd4f7f567a458",
     "grade": false,
     "grade_id": "cell-1725aad33842598e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 12\n",
    "test_input_len = 8\n",
    "test_ground_truth_output_len = 6\n",
    "\n",
    "# Create translator\n",
    "test_translator = Translator(input_size=10, \n",
    "                            embedding_size=100, \n",
    "                            hidden_size=30, \n",
    "                            output_size=12, \n",
    "                            num_layers=3)\n",
    "test_translator.to(device)\n",
    "\n",
    "# Create test input sentence and output sentence\n",
    "test_input_sentence = torch.ones(test_batch_size, test_input_len, dtype=torch.long, device=device)\n",
    "test_ground_truth_output = torch.ones(test_batch_size, test_ground_truth_output_len, dtype=torch.long, device=device)\n",
    "\n",
    "# Forward-prop through the translator\n",
    "out = test_translator(test_input_sentence, test_ground_truth_output)\n",
    "\n",
    "# Does the output have the correct shape?\n",
    "correct_shape = (test_batch_size, test_ground_truth_output_len, test_translator.output_size)\n",
    "assert out.shape == correct_shape, err_msg.format('`out`', tuple(out.shape), correct_shape)\n",
    "\n",
    "# Do the predictions sum to 1?\n",
    "test_pred_sums = torch.sum(out.exp(), dim=2).detach().cpu().numpy()\n",
    "err_msg = 'Predictions do not sum to 1:\\n {}'.format(test_pred_sums)\n",
    "assert np.allclose(test_pred_sums, np.ones_like(test_pred_sums)),  err_msg\n",
    "\n",
    "print('Test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e35c4cb9a70ce3063c0bfc0a3c8595a7",
     "grade": false,
     "grade_id": "cell-a2648e2cc194c3e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which steps should be taken in order to make use of word2vec embeddings in our models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2eee4740e2dfbcbfb45a08ef08bd1874",
     "grade": true,
     "grade_id": "cell-bbc68ff3a2bcbcba",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** A word2vec matrix $\\mathbf{E}$ must first be trained using a large dataset of sentences from the appropriate language. Then, our words must be encoded as one-hot vectors $\\mathbf{x}$ that have indexes that correspond to $\\mathbf{E}$. Finally, the one-hot encoded word vectors $\\mathbf{x}$ can be word2vec embedded using $\\mathbf{y} = \\mathbf{E}\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ce719f29c702bf16f00e76792ca3cb6",
     "grade": false,
     "grade_id": "cell-a3b7038020450c0f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The `forward_no_teacher` method will be used later for evaluating the translator's performance. Make sure you completely understand how it works before proceeding. The following cell shows some example usage. Since we didn't train the translator yet, its translations are mostly gibberish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "015698a5498f340228d1f7a2b8df898b",
     "grade": false,
     "grade_id": "cell-71cc095b9e95577c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:\t\t this is a test\n",
      "Predicted translation:\t paraguas probable o o éxito\n"
     ]
    }
   ],
   "source": [
    "# Create test sentence\n",
    "test_input_sentence = 'this is a test'\n",
    "print('Input sentence:\\t\\t', test_input_sentence)\n",
    "\n",
    "# Map to tensor of word indexes and add batch dimension\n",
    "test_tensor = sentence2tensor(input_lang, test_input_sentence).to(device)\n",
    "test_tensor = test_tensor[None, :]\n",
    "\n",
    "# Create translator\n",
    "test_translator = Translator(input_size=input_lang.n_words,\n",
    "                             embedding_size=100,\n",
    "                             hidden_size=128,\n",
    "                             output_size=output_lang.n_words,\n",
    "                             num_layers=3)\n",
    "test_translator.to(device)\n",
    "\n",
    "# Translate the input sentence (generate at most 5 words in the translation)\n",
    "test_tensor_translated = test_translator.forward_no_teacher(test_tensor, 5).cpu().numpy()\n",
    "\n",
    "# Remove batch dimension\n",
    "test_tensor_translated = test_tensor_translated[0]\n",
    "\n",
    "# Map from indexes to words\n",
    "word_list = [output_lang.index2word[idx] for idx in test_tensor_translated]\n",
    "\n",
    "# Join all words in a string and print it\n",
    "output_sentence = ' '.join(word_list)\n",
    "\n",
    "print('Predicted translation:\\t', output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b01baef0aa516b117cdcf0a96f74554",
     "grade": false,
     "grade_id": "cell-859e5248b5907028",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "Why do we get different translations every time we re-run the above cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee3e0005185edb7bc9d7e39f4ee7ae9f",
     "grade": true,
     "grade_id": "cell-82f800442f41bd8d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** Because the model parameters are initialized randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f1d43eaeeae5e6e1cc2da35fbe5efd7",
     "grade": false,
     "grade_id": "cell-912915a0b61dd530",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "What would happen if you tried translating the sentence \"this is extraordinary\"? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aeee0cc811e1b7eebe05d72e8aff3203",
     "grade": true,
     "grade_id": "cell-378967bd34f9ff95",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** We would get en error because our language data does not contain the english word \"extraordinary\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "110f0a7f77ec676451faab472cf7ffc2",
     "grade": false,
     "grade_id": "cell-cf018cd730905506",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d400bb66e04d92e996af02ea0171007c",
     "grade": false,
     "grade_id": "cell-51f306b5b4d1f042",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we're ready to train the model! Since at every time-step we're generating a prediction over possible words and comparing it to a ground-truth word, this can be seen as a classification problem. Because of this we'll use the `NLLLoss`, and the total loss will be the average loss value across all time-steps of the ground-truth sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f8f21aa527306e1805a661b44f5ec89",
     "grade": false,
     "grade_id": "cell-1d438d17fa64ff60",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10319f653d5d40ddf6a7d79210535455",
     "grade": false,
     "grade_id": "cell-4d4f92c545e608eb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Just like in task 1, we also first define a function for training in a single batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "596a98d969de1837ca312de4317def16",
     "grade": false,
     "grade_id": "cell-2521ffc63214fd17",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(translator, input_sequences, target_sequences, optimizer):\n",
    "    \"\"\"\n",
    "    Performs forward & backward passes for one batch, and takes a gradient step.\n",
    "\n",
    "    Inputs:\n",
    "        translator         - Translator object\n",
    "        input_sequences    - Batch of input sequences.\n",
    "                             LongTensor, shape (batch_size, seq_len). Holding the source language word indexes.\n",
    "        target_sequences   - Batch of target sequences.\n",
    "                             LongTensor, shape (batch_size, seq_len). Holding the true target language word indexes.\n",
    "        optimizer          - Pytorch optimizer object\n",
    "    Returns:\n",
    "        The average loss for the batch (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict distribution for each word position in the translated sentence\n",
    "    out = translator(input_sequences, target_sequences)\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate loss\n",
    "    out = out.permute(0, 2, 1)\n",
    "    loss = loss_fn(out[:, :, :-1], target_sequences[:, 1:])\n",
    "    \n",
    "    # Backward-prop and perform one optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "678fc76ec1d0e2c2d3e33f88b981bb81",
     "grade": false,
     "grade_id": "cell-5b74ad9ee3d2d964",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "Note that before computing the loss for a batch, we permute the dimensions of the output prediction from the translator. Why do we need to do this? \n",
    "\n",
    "*Tip*: read the [NLLLoss documentation](https://pytorch.org/docs/stable/nn.html#nllloss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6cc1a376b58325b35876785eedfe56a",
     "grade": true,
     "grade_id": "cell-ac30162be0f793e2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** Because the nn.NLLLoss function requires the order (batch_index, word_index, output_index), while the translator output has dimensions (batch_index, output_index, word_index)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "264e12818fee2a587950260e1276a9e0",
     "grade": false,
     "grade_id": "cell-0125e2d37c03c980",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We also define functions for computing our metrics of interest in the validation set and for plotting the metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad26c59c8de810943f4c1ad8697b623f",
     "grade": false,
     "grade_id": "cell-0ab220dc995eea05",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_on_validation_set(translator, val_data_loader):\n",
    "\n",
    "    n_processed, loss = 0, 0\n",
    "    for x_val, y_val in val_data_loader:\n",
    "        batch_size = x_val.shape[0]\n",
    "\n",
    "        # Put data in the correct device\n",
    "        x_val = x_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "\n",
    "        # Perform forward-prop with autograd disabled\n",
    "        with torch.no_grad():\n",
    "            val_out = translator(x_val, y_val)\n",
    "\n",
    "        # Calculate loss\n",
    "        val_out = val_out.permute(0, 2, 1)\n",
    "        batch_loss = loss_fn(val_out[:, :, :-1], y_val[:, 1:])*batch_size\n",
    "        \n",
    "        loss += batch_loss\n",
    "        n_processed += batch_size\n",
    "    \n",
    "    return loss/n_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0985da3cb071adab65c1451180ab2f7",
     "grade": false,
     "grade_id": "cell-da63411703d24d14",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_metrics(fig, ax, ns, train_losses, val_losses):\n",
    "\n",
    "    # Plot losses\n",
    "    ax.clear()\n",
    "    ax.plot(ns, train_losses)\n",
    "    ax.plot(ns, val_losses)\n",
    "    ax.plot(ns, [1]*len(ns), 'k--')\n",
    "    ax.set_title('Loss')\n",
    "    ax.legend(['Train','Validation', 'Validation loss threshold'])\n",
    "    ax.set_xlabel('Number of trained batches')    \n",
    "    ax.grid()\n",
    "    \n",
    "    \n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc5fa6d5b913a0afba5801224524d324",
     "grade": false,
     "grade_id": "cell-3f9b1c062f444a2d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that now the validation set metrics are computed using batches (instead of the entire dataset in one go, like we did in task 1) in order to reduce memory usage. It's also noteworthy that we're computing both losses using teacher forcing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e6b74fa61252b67fcd9d10d5c397f3f",
     "grade": false,
     "grade_id": "cell-bd4c43ab07d6c35c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "With these helper functions we can write the train function in a very similar way to task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0ea7958ff78bd6f00830ac4eb44dbe0",
     "grade": false,
     "grade_id": "cell-23110376805bb695",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "def train(translator, n_epochs, learning_rate, batch_size, train_dataset, val_dataset):\n",
    "    \n",
    "    # Setup the figure for plotting progress during training\n",
    "    %matplotlib notebook\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    plt.ion()\n",
    "    plot_interval = 100\n",
    "    \n",
    "    # Create arrays to average training metrics across batches\n",
    "    losses = []\n",
    "    \n",
    "    # Create dictionaries to hold the computed metrics in\n",
    "    train_data = {'losses': []}\n",
    "    val_data = {'losses': []}\n",
    "    \n",
    "    optimizer = Adam(translator.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    batch_idxs = []\n",
    "    \n",
    "    # Training loop\n",
    "    i_batch = 0\n",
    "    for n in range(n_epochs):\n",
    "        for i, (x_batch, y_batch) in enumerate(train_data_loader):\n",
    "            i_batch += 1\n",
    "            \n",
    "            # Put data in the correct device\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # Compute loss and outputs\n",
    "            loss = train_batch(translator, x_batch, y_batch, optimizer)\n",
    "            \n",
    "            # Aggregate for later averaging\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # Compute metrics and plot after every `plot_interval` batches\n",
    "            if i % plot_interval == 0:\n",
    "              \n",
    "                val_loss = compute_metrics_on_validation_set(translator, val_data_loader)\n",
    "                \n",
    "                val_data['losses'].append(val_loss)\n",
    "                train_data['losses'].append(sum(losses)/len(losses))\n",
    "                batch_idxs.append(i_batch)\n",
    "\n",
    "                losses = []\n",
    "\n",
    "                plot_metrics(fig, ax, batch_idxs, train_data['losses'], val_data['losses'])\n",
    "                \n",
    "    return y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f91cb5336ca4537fbf022992632cd909",
     "grade": false,
     "grade_id": "cell-fd36bbe465cd74d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "And we can now actually perform the training! Create a `Translator` object in the next cell and train it using the `train` function. Tune the hyper-parameters so that the validation loss ends below 1.\n",
    "\n",
    "**Tips**:\n",
    "- Tuning the hyper-parameters (number of hidden units, learning rate, batch size, etc) will take some trial-and-error. Try simple things first, and then once you manage to train them, start scaling up. Also, have in mind the bias-variance tradeoff mentioned in the lectures.\n",
    "- When tuning the learning rate, focus first on being able to decrease the training loss. Keep decreasing the learning rate until that starts happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "568b515d4bf09d5de649e81ab40799f9",
     "grade": true,
     "grade_id": "cell-7c18b8ba0338ce9e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "translator = Translator(input_size=input_lang.n_words,\n",
    "                             embedding_size=30,\n",
    "                             hidden_size=96,\n",
    "                             output_size=output_lang.n_words,\n",
    "                             num_layers=3)\n",
    "translator.to(device)\n",
    "train(translator, 50, 0.001, 64, train_dataset, val_dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "789e99e0c508d5552130347eb345db7b",
     "grade": false,
     "grade_id": "cell-dbcee1678cbfb5d4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Make sure you get the validation loss down to at least 1.0 before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db556efe809c1afc0bb9ad0c998b0663",
     "grade": false,
     "grade_id": "cell-bb406463353d0579",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35edaf2bc1257eb910c7608a2900e883",
     "grade": false,
     "grade_id": "cell-fd131b12fbda2d16",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we can evaluate how well our translator performs in unseen sentences. The following functions can be used to streamline the translation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dffa9f741679ff11472bb752eca49334",
     "grade": false,
     "grade_id": "cell-c3e14eb95c6c1574",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def tensor2str(t, lang):\n",
    "    # Remove batch dimension\n",
    "    t = t[0]\n",
    "    \n",
    "    # Get numpy array\n",
    "    t = t.cpu().numpy()\n",
    "    \n",
    "    # Map each index to its corresponding word\n",
    "    list_words = list(map(lambda i: lang.index2word[i], t))\n",
    "    \n",
    "    sentence = ' '.join(list_words)\n",
    "    return sentence.replace('PAD', '').replace('EOS', '').replace('SOS', '').strip()\n",
    "\n",
    "def translate_sentence(translator, in_sentence, n_max_preds=10):\n",
    "    # Transform input sentence into its tensor representation (and add batch dimension)\n",
    "    input_tensor = sentence2tensor(input_lang, in_sentence)[None, :].to(device=device)\n",
    "    \n",
    "    # Translate using the learned translator\n",
    "    output_tensor = translator.forward_no_teacher(input_tensor, n_max_preds)\n",
    "    \n",
    "    # Transform back to a sentence\n",
    "    out_sentence = tensor2str(output_tensor, output_lang)\n",
    "    \n",
    "    return out_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "502da6deec5f58ed72c21625133900c5",
     "grade": false,
     "grade_id": "cell-c7b3f86a3d43ceb5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Using them, it's straightforward to translate new sentences from the test set. Note that we're not using teacher forcing anymore, so it's natural to observe some drop in performance (we're also not printing any special word tokens, like `<SOS>`, or `<PAD>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01e5329169254de54a55b4d36537cdfb",
     "grade": false,
     "grade_id": "cell-459f18c4c522873c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t\t they are about to start\n",
      "Translation:\t ellos están por empezar\n",
      "Prediction:\t a lo de empezar por empezar\n",
      "\n",
      "Input:\t\t he finished breakfast\n",
      "Translation:\t él terminó su desayuno\n",
      "Prediction:\t sus libros\n",
      "\n",
      "Input:\t\t whose food is this\n",
      "Translation:\t de quién es esta comida\n",
      "Prediction:\t de esta libro está ocupado de esto\n",
      "\n",
      "Input:\t\t do you like snow\n",
      "Translation:\t te gusta la nieve\n",
      "Prediction:\t a verte\n",
      "\n",
      "Input:\t\t i ll buy one\n",
      "Translation:\t voy a comprar uno\n",
      "Prediction:\t este libro\n",
      "\n",
      "Input:\t\t he often comes late\n",
      "Translation:\t suele venir tarde\n",
      "Prediction:\t a la cama tarde\n",
      "\n",
      "Input:\t\t i like walking by myself\n",
      "Translation:\t me gusta caminar solo\n",
      "Prediction:\t a mí caminar aquí me hacer\n",
      "\n",
      "Input:\t\t is tom still sleeping\n",
      "Translation:\t tom sigue durmiendo\n",
      "Prediction:\t tom todavía todavía está durmiendo\n",
      "\n",
      "Input:\t\t i d like to buy that one\n",
      "Translation:\t quisiera comprar ese\n",
      "Prediction:\t eso comprar comprar eso\n",
      "\n",
      "Input:\t\t tom isn t ready to be a father\n",
      "Translation:\t tom no está preparado para ser padre\n",
      "Prediction:\t tom no está listo para ser tu padre\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_translations = 10\n",
    "for n in range(n_translations):\n",
    "    i = np.random.randint((len(test_dataset)))\n",
    "    x, y = test_dataset[i]\n",
    "    input_sentence = tensor2str(x[None,:], input_lang)\n",
    "    output_sentence = tensor2str(y[None,:], output_lang)\n",
    "    print('Input:\\t\\t', input_sentence)\n",
    "    print('Translation:\\t', output_sentence)\n",
    "    print('Prediction:\\t', translate_sentence(translator, input_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32885b7548a528a3717b836ae9619a6f",
     "grade": false,
     "grade_id": "cell-fe8f404a74761ed5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "And we can also translate other sentences we want to (just remember that the input sentence can only contain words from the vocabulary we used to train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es una película aquí una verdad'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_sentence(translator, 'this is a test sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83c62244957792e4614850fa34f65b28",
     "grade": false,
     "grade_id": "cell-09a52180cf6aa5ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Finally, in order to get a higher-level view of the performance of your translator across the entire test set, we can compute its [BLEU score](https://en.wikipedia.org/wiki/BLEU). This is a metric whose value ranges from 0 to 1, higher values meaning that the translations are closer to ground-truth. However, only a perfect match between prediction and ground-truth yields a value of 1, so very few translations will be this high. The original [BLEU paper](https://www.aclweb.org/anthology/P02-1040) gives one report of a human baseline for a dataset they used:\n",
    "\n",
    "> (...) on a test corpus of about 500 sentences (40 general news stories), a human translator scored 0.3468 against four references and scored 0.2571 against two references.\n",
    "\n",
    "To compute this metric, we use the `nltk` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a43315e13f0bf963f2a6b09627ccdd89",
     "grade": false,
     "grade_id": "cell-5df1c6895c7e3fc7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 sentences processed...\n",
      "2000 sentences processed...\n",
      "3000 sentences processed...\n",
      "4000 sentences processed...\n",
      "5000 sentences processed...\n",
      "Finished! The BLEU score is: 0.1769754222935331\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "references = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(test_dataset):\n",
    "    input_sentence = tensor2str(x[None, :], input_lang)\n",
    "    output_sentence = tensor2str(y[None, :], output_lang)\n",
    "    translated = translate_sentence(translator, input_sentence)   \n",
    "    references.append([output_sentence.split()])\n",
    "    preds.append(translated.split())\n",
    "    \n",
    "    if i % 1000 == 0 and i != 0:\n",
    "        print(i, 'sentences processed...')\n",
    "\n",
    "bleu = corpus_bleu(references, preds)\n",
    "print('Finished! The BLEU score is: {}'.format(bleu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9ca78db00bfad99e7575ed42da16b1b",
     "grade": false,
     "grade_id": "cell-9b25041f9e121f34",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For us, a value ranging from 0.1 - 0.2 is reasonable (note that performance can be sensitive to the initialization of the network, so it might vary among different runs of the same optimization), specially since we're only comparing to one reference translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e9ca833440393726c6a7d50e284ca64",
     "grade": false,
     "grade_id": "cell-71c02eae358d2a85",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You have now completed HA2. **Good job!**\n",
    "\n",
    "**Final Question:**\n",
    "What changes could you make to the translator (e.g. architecture, optimization, data used, etc) to improve the end result of your translations? Make three suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88e3fbe6f3b37634091a974f5295688b",
     "grade": true,
     "grade_id": "cell-1912255711ce6aa8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** \n",
    "\n",
    "1. More data\n",
    "2. Use some kind of attention, which has proven to work very well on ML problems\n",
    "3. GRU layers?\n",
    "4. Output layers?\n",
    "5. Adaptable learning rate?\n",
    "6. Dropout in GRU (it is starting to overfit)?\n",
    "7. Larger hidden_size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
